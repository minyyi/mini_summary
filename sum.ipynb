{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe55bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import fitz  # pymupdf\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict, List, Dict, Any\n",
    "import pickle\n",
    "import os\n",
    "import tempfile\n",
    "from dotenv import load_dotenv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e5d39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 14:11:28.085 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "st.set_page_config(\n",
    "    page_title=\"PDF ë¶„ì„ AI ì–´ì‹œìŠ¤í„´íŠ¸\",\n",
    "    page_icon=\"ğŸ¤–\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70321de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f329ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o', streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "722e9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_session_state():\n",
    "    \"\"\"ì„¸ì…˜ ìƒíƒœ ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”\"\"\"\n",
    "    if 'chunks' not in st.session_state:\n",
    "        st.session_state.chunks = []\n",
    "    if 'index' not in st.session_state:\n",
    "        st.session_state.index = None\n",
    "    if 'embedding_model' not in st.session_state:\n",
    "        st.session_state.embedding_model = None\n",
    "    if 'metadatas' not in st.session_state:\n",
    "        st.session_state.metadatas = []\n",
    "    if 'file_processed' not in st.session_state:\n",
    "        st.session_state.file_processed = False\n",
    "    if 'chat_history' not in st.session_state:\n",
    "        st.session_state.chat_history = []\n",
    "    if 'agent_graph' not in st.session_state:\n",
    "        st.session_state.agent_graph = None\n",
    "    if 'uploaded_filename' not in st.session_state:\n",
    "        st.session_state.uploaded_filename = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9277e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 14:11:28.710 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.710 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.710 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "init_session_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2acea5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: List[Any]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== PDF ë¶„ì„ Streamlit ì•± ==============\n",
    "import streamlit as st\n",
    "import fitz  # pymupdf\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict, List, Dict, Any\n",
    "import pickle\n",
    "import os\n",
    "import tempfile\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# í˜ì´ì§€ ì„¤ì •\n",
    "st.set_page_config(\n",
    "    page_title=\"íŒŒì¼ ë¶„ì„ AI ì–´ì‹œìŠ¤í„´íŠ¸\",\n",
    "    page_icon=\"ğŸ¤–\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# í™˜ê²½ ì„¤ì •\n",
    "load_dotenv()\n",
    "\n",
    "# ============== ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ==============\n",
    "def init_session_state():\n",
    "    \"\"\"ì„¸ì…˜ ìƒíƒœ ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”\"\"\"\n",
    "    if 'chunks' not in st.session_state:\n",
    "        st.session_state.chunks = []\n",
    "    if 'index' not in st.session_state:\n",
    "        st.session_state.index = None\n",
    "    if 'embedding_model' not in st.session_state:\n",
    "        st.session_state.embedding_model = None\n",
    "    if 'metadatas' not in st.session_state:\n",
    "        st.session_state.metadatas = []\n",
    "    if 'file_processed' not in st.session_state:\n",
    "        st.session_state.file_processed = False\n",
    "    if 'chat_history' not in st.session_state:\n",
    "        st.session_state.chat_history = []\n",
    "    if 'agent_graph' not in st.session_state:\n",
    "        st.session_state.agent_graph = None\n",
    "    if 'uploaded_filename' not in st.session_state:\n",
    "        st.session_state.uploaded_filename = \"\"\n",
    "    if 'file_metadata' not in st.session_state:\n",
    "        st.session_state.file_metadata = {}\n",
    "    if 'pdf_metadata' not in st.session_state:\n",
    "        st.session_state.pdf_metadata = {}\n",
    "    if 'current_input' not in st.session_state:\n",
    "        st.session_state.current_input = \"\"\n",
    "    if 'processing' not in st.session_state:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "# ì´ˆê¸°í™” ì‹¤í–‰\n",
    "init_session_state()\n",
    "\n",
    "# ============== íƒ€ì… ì •ì˜ ==============\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[Any]\n",
    "\n",
    "# ============== íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ==============\n",
    "\n",
    "def extract_text_from_file(uploaded_file):\n",
    "    \"\"\"ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\"\"\"\n",
    "    file_type = uploaded_file.type\n",
    "    file_name = uploaded_file.name.lower()\n",
    "    \n",
    "    # ê¸°ë³¸ íŒŒì¼ ì •ë³´ ì €ì¥\n",
    "    st.session_state.file_metadata = {\n",
    "        'filename': uploaded_file.name,\n",
    "        'file_type': file_type,\n",
    "        'file_size': uploaded_file.size,\n",
    "        'file_size_mb': round(uploaded_file.size / (1024*1024), 2)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if file_type == \"application/pdf\" or file_name.endswith('.pdf'):\n",
    "            return extract_text_with_fitz(uploaded_file)\n",
    "        \n",
    "        elif file_type == \"text/plain\" or file_name.endswith(('.txt', '.md', '.py', '.js', '.html', '.css', '.json', '.xml', '.csv')):\n",
    "            # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬\n",
    "            content = uploaded_file.read()\n",
    "            if isinstance(content, bytes):\n",
    "                # ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„\n",
    "                for encoding in ['utf-8', 'cp949', 'euc-kr', 'latin-1']:\n",
    "                    try:\n",
    "                        text = content.decode(encoding)\n",
    "                        st.success(f\"âœ… í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì™„ë£Œ! ({encoding} ì¸ì½”ë”©)\")\n",
    "                        \n",
    "                        # í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€\n",
    "                        lines = text.split('\\n')\n",
    "                        words = text.split()\n",
    "                        \n",
    "                        # íŒŒì¼ í™•ì¥ìë¡œ íŒŒì¼ ìœ í˜• íŒë‹¨\n",
    "                        file_ext = file_name.split('.')[-1] if '.' in file_name else 'txt'\n",
    "                        file_type_name = {\n",
    "                            'py': 'Python ì½”ë“œ',\n",
    "                            'js': 'JavaScript ì½”ë“œ', \n",
    "                            'html': 'HTML ë¬¸ì„œ',\n",
    "                            'css': 'CSS ìŠ¤íƒ€ì¼ì‹œíŠ¸',\n",
    "                            'json': 'JSON ë°ì´í„°',\n",
    "                            'xml': 'XML ë¬¸ì„œ',\n",
    "                            'csv': 'CSV ë°ì´í„°',\n",
    "                            'md': 'Markdown ë¬¸ì„œ',\n",
    "                            'txt': 'í…ìŠ¤íŠ¸ ë¬¸ì„œ'\n",
    "                        }.get(file_ext, 'í…ìŠ¤íŠ¸ íŒŒì¼')\n",
    "                        \n",
    "                        st.session_state.file_metadata.update({\n",
    "                            'encoding': encoding,\n",
    "                            'lines': len(lines),\n",
    "                            'words': len(words),\n",
    "                            'characters': len(text),\n",
    "                            'file_type_name': file_type_name,\n",
    "                            'extension': file_ext.upper(),\n",
    "                            'paragraphs': len([line for line in lines if line.strip()]),\n",
    "                            'empty_lines': len([line for line in lines if not line.strip()])\n",
    "                        })\n",
    "                        \n",
    "                        return text\n",
    "                    except UnicodeDecodeError:\n",
    "                        continue\n",
    "                st.error(\"âŒ í…ìŠ¤íŠ¸ íŒŒì¼ ì¸ì½”ë”©ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                return \"\"\n",
    "            else:\n",
    "                return str(content)\n",
    "        \n",
    "        else:\n",
    "            st.error(f\"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_type}\")\n",
    "            return \"\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        st.error(f\"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_with_fitz(pdf_file):\n",
    "    \"\"\"PyMuPDFë¡œ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ\"\"\"\n",
    "    try:\n",
    "        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:\n",
    "            tmp_file.write(pdf_file.read())\n",
    "            tmp_path = tmp_file.name\n",
    "        \n",
    "        doc = fitz.open(tmp_path)\n",
    "        \n",
    "        # PDF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ\n",
    "        metadata = doc.metadata\n",
    "        st.session_state.pdf_metadata = {\n",
    "            'title': metadata.get('title', 'ì œëª© ì—†ìŒ'),\n",
    "            'author': metadata.get('author', 'ì‘ì„±ì ì—†ìŒ'),\n",
    "            'subject': metadata.get('subject', 'ì£¼ì œ ì—†ìŒ'),\n",
    "            'creator': metadata.get('creator', 'ìƒì„± í”„ë¡œê·¸ë¨ ì—†ìŒ'),\n",
    "            'producer': metadata.get('producer', 'ì œì‘ í”„ë¡œê·¸ë¨ ì—†ìŒ'),\n",
    "            'creationDate': metadata.get('creationDate', 'ìƒì„±ì¼ ì—†ìŒ'),\n",
    "            'modDate': metadata.get('modDate', 'ìˆ˜ì •ì¼ ì—†ìŒ'),\n",
    "            'total_pages': len(doc)\n",
    "        }\n",
    "        \n",
    "        # ì§„í–‰ ìƒí™© í‘œì‹œ\n",
    "        progress_bar = st.progress(0)\n",
    "        status_text = st.empty()\n",
    "        \n",
    "        full_text = \"\"\n",
    "        total_pages = len(doc)\n",
    "        \n",
    "        for page_num in range(total_pages):\n",
    "            progress = (page_num + 1) / total_pages\n",
    "            progress_bar.progress(progress)\n",
    "            status_text.text(f\"í˜ì´ì§€ {page_num + 1}/{total_pages} ì²˜ë¦¬ ì¤‘...\")\n",
    "            \n",
    "            page = doc[page_num]\n",
    "            text = page.get_text()\n",
    "            \n",
    "            if text and text.strip():\n",
    "                text = text.replace('\\x00', '')\n",
    "                text = text.replace('\\ufeff', '')\n",
    "                text = text.replace('\\r\\n', '\\n')\n",
    "                text = text.replace('\\r', '\\n')\n",
    "                full_text += text + \"\\n\\n\"\n",
    "        \n",
    "        doc.close()\n",
    "        os.unlink(tmp_path)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ\n",
    "        \n",
    "        progress_bar.progress(1.0)\n",
    "        status_text.text(f\"âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ! ì´ {len(full_text)} ê¸€ì\")\n",
    "        time.sleep(1)\n",
    "        progress_bar.empty()\n",
    "        status_text.empty()\n",
    "        \n",
    "        return full_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def chunk_text(text, chunk_size=2000, overlap=100):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if not text.strip():\n",
    "        return []\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end].strip()\n",
    "        \n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        start = end - overlap\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def create_vectorstore(chunks):\n",
    "    \"\"\"FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\"\"\"\n",
    "    if not chunks:\n",
    "        return None, None, None\n",
    "    \n",
    "    try:\n",
    "        with st.spinner('ğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)'):\n",
    "            embedding_model = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "            embeddings = embedding_model.embed_documents(chunks)\n",
    "            embeddings = np.array(embeddings).astype('float32')\n",
    "            \n",
    "            # FAISS ì¸ë±ìŠ¤ ìƒì„±\n",
    "            dimension = embeddings.shape[1]\n",
    "            index = faiss.IndexFlatL2(dimension)\n",
    "            index.add(embeddings)\n",
    "            \n",
    "            # ë©”íƒ€ë°ì´í„° ìƒì„±\n",
    "            metadatas = []\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                metadatas.append({\n",
    "                    'chunk_id': i,\n",
    "                    'chunk_size': len(chunk),\n",
    "                    'preview': chunk[:100] + \"...\" if len(chunk) > 100 else chunk\n",
    "                })\n",
    "        \n",
    "        st.success(f\"âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ! {index.ntotal}ê°œ ë²¡í„° ì €ì¥\")\n",
    "        return index, embedding_model, metadatas\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"âŒ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì˜¤ë¥˜: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def safe_search_documents(query, k=3):\n",
    "    \"\"\"ì•ˆì „í•œ ë¬¸ì„œ ê²€ìƒ‰\"\"\"\n",
    "    try:\n",
    "        if (not hasattr(st.session_state, 'index') or \n",
    "            st.session_state.index is None or \n",
    "            not hasattr(st.session_state, 'embedding_model') or\n",
    "            st.session_state.embedding_model is None):\n",
    "            return []\n",
    "        \n",
    "        query_embedding = st.session_state.embedding_model.embed_query(query)\n",
    "        query_embedding = np.array([query_embedding]).astype('float32')\n",
    "        \n",
    "        distances, indices = st.session_state.index.search(query_embedding, k)\n",
    "        \n",
    "        results = []\n",
    "        for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "            if idx < len(st.session_state.chunks):\n",
    "                results.append({\n",
    "                    'chunk_id': idx,\n",
    "                    'content': st.session_state.chunks[idx],\n",
    "                    'score': 1.0 - (distance / 2.0),\n",
    "                    'metadata': st.session_state.metadatas[idx] if idx < len(st.session_state.metadatas) else {}\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        return []\n",
    "\n",
    "# ============== LangGraph Tools ==============\n",
    "\n",
    "@tool\n",
    "def search_uploaded_documents(query: str) -> str:\n",
    "    \"\"\"ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "        results = safe_search_documents(query, 3)\n",
    "        \n",
    "        if not results:\n",
    "            return f\"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            formatted_results.append(\n",
    "                f\"[ê²€ìƒ‰ê²°ê³¼ {i}] (ìœ ì‚¬ë„: {result['score']:.3f})\\n\"\n",
    "                f\"{result['content'][:400]}{'...' if len(result['content']) > 400 else ''}\\n\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n\".join(formatted_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"íŒŒì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def web_search_tool(query: str) -> str:\n",
    "    \"\"\"ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        from langchain_community.tools import DuckDuckGoSearchRun\n",
    "        search_tool = DuckDuckGoSearchRun()\n",
    "        results = search_tool.run(query)\n",
    "        return f\"ğŸŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼:\\n\\n{results}\"\n",
    "    except ImportError:\n",
    "        return f\"\"\"ğŸ” \"{query}\" ê²€ìƒ‰ ë§í¬:\n",
    "â€¢ Google: https://www.google.com/search?q={query.replace(' ', '+')}\n",
    "â€¢ ë„¤ì´ë²„: https://search.naver.com/search.naver?query={query.replace(' ', '+')}\n",
    "\n",
    "ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰: pip install duckduckgo-search\"\"\"\n",
    "    except Exception as e:\n",
    "        return f\"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def general_chat_tool(question: str) -> str:\n",
    "    \"\"\"ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "        response = llm.invoke([HumanMessage(content=question)])\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def summarize_content_tool() -> str:\n",
    "    \"\"\"ì—…ë¡œë“œëœ íŒŒì¼ì˜ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        if (not hasattr(st.session_state, 'file_processed') or \n",
    "            not st.session_state.file_processed or\n",
    "            not hasattr(st.session_state, 'chunks') or\n",
    "            not st.session_state.chunks):\n",
    "            return \"ìš”ì•½í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "        # ì²˜ìŒ 5ê°œ ì²­í¬ë¥¼ ìš”ì•½ (ë” ë§ì€ ë‚´ìš©)\n",
    "        content = \"\\n\".join(st.session_state.chunks[:5])\n",
    "        \n",
    "        if not content.strip():\n",
    "            return \"ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì²˜ë¦¬\n",
    "        if len(content) > 8000:\n",
    "            content = content[:8000] + \"...\"\n",
    "        \n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "        \n",
    "        # ê°„ë‹¨í•œ ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "        prompt = f\"\"\"ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "{content}\n",
    "\n",
    "ìš”ì•½:\"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        return response.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_document_info_tool() -> str:\n",
    "    \"\"\"í˜„ì¬ ë¡œë“œëœ íŒŒì¼ì˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "        if not hasattr(st.session_state, 'chunks') or not st.session_state.chunks:\n",
    "            return \"íŒŒì¼ ì²˜ë¦¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # ê¸°ë³¸ í†µê³„ ì •ë³´\n",
    "        total_chars = sum(len(chunk) for chunk in st.session_state.chunks)\n",
    "        filename = getattr(st.session_state, 'uploaded_filename', 'ì•Œ ìˆ˜ ì—†ìŒ')\n",
    "        \n",
    "        # íŒŒì¼ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "        file_meta = getattr(st.session_state, 'file_metadata', {})\n",
    "        pdf_meta = getattr(st.session_state, 'pdf_metadata', {})\n",
    "        \n",
    "        info_text = f\"\"\"ğŸ“„ **íŒŒì¼ ì •ë³´**\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "ğŸ“ **ê¸°ë³¸ ì •ë³´**\n",
    "â€¢ íŒŒì¼ëª…: {filename}\n",
    "â€¢ íŒŒì¼ í˜•ì‹: {file_meta.get('file_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "â€¢ íŒŒì¼ í¬ê¸°: {file_meta.get('file_size_mb', 0)} MB ({file_meta.get('file_size', 0):,} bytes)\n",
    "\"\"\"\n",
    "\n",
    "        # PDF ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°\n",
    "        if pdf_meta:\n",
    "            info_text += f\"\"\"\n",
    "ğŸ“– **PDF ë¬¸ì„œ ì •ë³´**\n",
    "â€¢ ì œëª©: {pdf_meta.get('title', 'ì œëª© ì—†ìŒ')}\n",
    "â€¢ ì‘ì„±ì: {pdf_meta.get('author', 'ì‘ì„±ì ì—†ìŒ')}\n",
    "â€¢ ì£¼ì œ: {pdf_meta.get('subject', 'ì£¼ì œ ì—†ìŒ')}\n",
    "â€¢ ì´ í˜ì´ì§€ ìˆ˜: {pdf_meta.get('total_pages', 'ì•Œ ìˆ˜ ì—†ìŒ')}í˜ì´ì§€\n",
    "â€¢ ìƒì„± í”„ë¡œê·¸ë¨: {pdf_meta.get('creator', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "â€¢ ì œì‘ í”„ë¡œê·¸ë¨: {pdf_meta.get('producer', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "â€¢ ìƒì„±ì¼: {pdf_meta.get('creationDate', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "â€¢ ìˆ˜ì •ì¼: {pdf_meta.get('modDate', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "\"\"\"\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ íŒŒì¼ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°\n",
    "        if 'lines' in file_meta:\n",
    "            info_text += f\"\"\"\n",
    "ğŸ“ **{file_meta.get('file_type_name', 'í…ìŠ¤íŠ¸ íŒŒì¼')} ì •ë³´**\n",
    "â€¢ íŒŒì¼ í˜•ì‹: {file_meta.get('extension', 'TXT')} íŒŒì¼\n",
    "â€¢ ì¸ì½”ë”©: {file_meta.get('encoding', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "â€¢ ì´ ì¤„ ìˆ˜: {file_meta.get('lines', 0):,}ì¤„\n",
    "â€¢ ì´ ë‹¨ì–´ ìˆ˜: {file_meta.get('words', 0):,}ê°œ\n",
    "â€¢ ì´ ë¬¸ì ìˆ˜: {file_meta.get('characters', 0):,}ì\n",
    "â€¢ ë‚´ìš©ì´ ìˆëŠ” ì¤„: {file_meta.get('paragraphs', 0):,}ì¤„\n",
    "â€¢ ë¹ˆ ì¤„: {file_meta.get('empty_lines', 0):,}ì¤„\n",
    "\"\"\"\n",
    "\n",
    "        info_text += f\"\"\"\n",
    "ğŸ”§ **ë¶„ì„ ì •ë³´**\n",
    "â€¢ ì²­í¬ ìˆ˜: {len(st.session_state.chunks):,}ê°œ\n",
    "â€¢ ì´ í…ìŠ¤íŠ¸ ê¸¸ì´: {total_chars:,}ì\n",
    "â€¢ í‰ê·  ì²­í¬ í¬ê¸°: {total_chars // len(st.session_state.chunks):,}ì\n",
    "\n",
    "ğŸ› ï¸ **ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥**\n",
    "â€¢ ğŸ“ íŒŒì¼ ë‚´ìš© ìš”ì•½\n",
    "â€¢ ğŸ” í‚¤ì›Œë“œ/ë‚´ìš© ê²€ìƒ‰  \n",
    "â€¢ ğŸŒ ì›¹ ê²€ìƒ‰ê³¼ ë¹„êµ\n",
    "â€¢ ğŸ’¬ íŒŒì¼ ê´€ë ¨ ì§ˆì˜ì‘ë‹µ\n",
    "\n",
    "ğŸ’¡ **ì˜ˆì‹œ ì§ˆë¬¸**\n",
    "â€¢ \"ì´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜\"\n",
    "â€¢ \"íŠ¹ì • í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•´ì¤˜\"\n",
    "â€¢ \"ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ì°¾ì•„ì¤˜\"\n",
    "\"\"\"\n",
    "\n",
    "        return info_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "# ============== LangGraph ê·¸ë˜í”„ ==============\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ - tool calling ì œê±°ë¡œ í•­ìƒ END\"\"\"\n",
    "    return END\n",
    "\n",
    "def agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"LLM ì—ì´ì „íŠ¸ í•¨ìˆ˜ - í‚¤ì›Œë“œ ê¸°ë°˜ ë¼ìš°íŒ…ìœ¼ë¡œ tool calling ì—ëŸ¬ ë°©ì§€\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ\n",
    "    if not messages:\n",
    "        return {\"messages\": [AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\")]}\n",
    "    \n",
    "    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°\n",
    "    user_message = \"\"\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            user_message = msg.content\n",
    "            break\n",
    "    \n",
    "    if not user_message:\n",
    "        return {\"messages\": messages + [AIMessage(content=\"ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\")]}\n",
    "    \n",
    "    try:\n",
    "        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¼ìš°íŒ…ìœ¼ë¡œ tool calling ëŒ€ì‹  ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ\n",
    "        user_lower = user_message.lower()\n",
    "        \n",
    "        # íŒŒì¼ ê´€ë ¨ í‚¤ì›Œë“œ\n",
    "        file_keywords = ['íŒŒì¼', 'ë¬¸ì„œ', 'ìš”ì•½', 'ì •ë³´', 'ë‚´ìš©', 'ë¶„ì„']\n",
    "        web_keywords = ['ê²€ìƒ‰', 'ë‰´ìŠ¤', 'ìµœì‹ ', 'ë‚ ì”¨', 'í˜„ì¬', 'ì°¾ì•„']\n",
    "        \n",
    "        response_content = \"\"\n",
    "        \n",
    "        # íŒŒì¼ì´ ì—…ë¡œë“œëœ ìƒíƒœì—ì„œ íŒŒì¼ ê´€ë ¨ ì§ˆë¬¸\n",
    "        if st.session_state.file_processed and any(keyword in user_lower for keyword in file_keywords):\n",
    "            if 'ìš”ì•½' in user_lower:\n",
    "                # íŒŒì¼ ìš”ì•½\n",
    "                try:\n",
    "                    if st.session_state.chunks:\n",
    "                        content = \"\\n\".join(st.session_state.chunks[:5])\n",
    "                        if len(content) > 8000:\n",
    "                            content = content[:8000] + \"...\"\n",
    "                        \n",
    "                        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "                        prompt = f\"ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:\\n\\n{content}\\n\\nìš”ì•½:\"\n",
    "                        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "                        response_content = response.content\n",
    "                    else:\n",
    "                        response_content = \"ìš”ì•½í•  íŒŒì¼ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "                except Exception as e:\n",
    "                    response_content = f\"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "                    \n",
    "            elif 'ì •ë³´' in user_lower:\n",
    "                # íŒŒì¼ ì •ë³´\n",
    "                response_content = get_document_info_tool_direct()\n",
    "                \n",
    "            else:\n",
    "                # íŒŒì¼ ê²€ìƒ‰\n",
    "                try:\n",
    "                    results = safe_search_documents(user_message, 3)\n",
    "                    if results:\n",
    "                        formatted_results = []\n",
    "                        for i, result in enumerate(results, 1):\n",
    "                            formatted_results.append(\n",
    "                                f\"[ê²€ìƒ‰ê²°ê³¼ {i}] (ìœ ì‚¬ë„: {result['score']:.3f})\\n\"\n",
    "                                f\"{result['content'][:400]}{'...' if len(result['content']) > 400 else ''}\\n\"\n",
    "                            )\n",
    "                        response_content = \"\\n\".join(formatted_results)\n",
    "                    else:\n",
    "                        response_content = f\"'{user_message}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "                except Exception as e:\n",
    "                    response_content = f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "        \n",
    "        # ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸\n",
    "        elif any(keyword in user_lower for keyword in web_keywords):\n",
    "            try:\n",
    "                from langchain_community.tools import DuckDuckGoSearchRun\n",
    "                search_tool = DuckDuckGoSearchRun()\n",
    "                results = search_tool.run(user_message)\n",
    "                response_content = f\"ğŸŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼:\\n\\n{results}\"\n",
    "            except ImportError:\n",
    "                response_content = f\"\"\"ğŸ” \"{user_message}\" ê²€ìƒ‰ ë§í¬:\n",
    "â€¢ Google: https://www.google.com/search?q={user_message.replace(' ', '+')}\n",
    "â€¢ ë„¤ì´ë²„: https://search.naver.com/search.naver?query={user_message.replace(' ', '+')}\n",
    "\n",
    "ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰: pip install duckduckgo-search\"\"\"\n",
    "            except Exception as e:\n",
    "                response_content = f\"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "        \n",
    "        # ì¼ë°˜ ì§ˆë¬¸\n",
    "        else:\n",
    "            try:\n",
    "                llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "                response = llm.invoke([HumanMessage(content=user_message)])\n",
    "                response_content = response.content\n",
    "            except Exception as e:\n",
    "                response_content = f\"ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "        \n",
    "        # AI ì‘ë‹µ ìƒì„±\n",
    "        ai_response = AIMessage(content=response_content)\n",
    "        return {\"messages\": messages + [ai_response]}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_response = AIMessage(content=f\"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")\n",
    "        return {\"messages\": messages + [error_response]}\n",
    "\n",
    "# ê·¸ë˜í”„ ë¹Œë” ìƒì„± (tool calling ì œê±°)\n",
    "graph_builder = StateGraph(AgentState)\n",
    "graph_builder.add_node('agent', agent)\n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "graph_builder.add_edge('agent', END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# ============== ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜ ==============\n",
    "\n",
    "def process_user_input():\n",
    "    \"\"\"ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜ - ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€\"\"\"\n",
    "    # ì²˜ë¦¬ ì¤‘ì´ë©´ ë¬´ì‹œ\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    user_input = st.session_state.current_input.strip()\n",
    "    if not user_input:\n",
    "        return\n",
    "    \n",
    "    # ì²˜ë¦¬ ìƒíƒœ ì„¤ì •\n",
    "    st.session_state.processing = True\n",
    "    \n",
    "    try:\n",
    "        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "        st.session_state.chat_history.append((\"user\", user_input))\n",
    "        \n",
    "        # AI ì‘ë‹µ ìƒì„±\n",
    "        if st.session_state.agent_graph is None:\n",
    "            st.session_state.agent_graph = graph\n",
    "        \n",
    "        # ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘ (ì´ì „ ë©”ì‹œì§€ ì²´ì¸ ë¬¸ì œ ë°©ì§€)\n",
    "        initial_state = {\"messages\": [HumanMessage(content=user_input)]}\n",
    "        result = st.session_state.agent_graph.invoke(initial_state)\n",
    "        \n",
    "        # ì‘ë‹µ ì¶”ì¶œ (ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ì°¾ê¸°)\n",
    "        ai_response = None\n",
    "        if result and \"messages\" in result:\n",
    "            # ì—­ìˆœìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ ì²« ë²ˆì§¸ AI ë©”ì‹œì§€ ì°¾ê¸°\n",
    "            for msg in reversed(result[\"messages\"]):\n",
    "                if isinstance(msg, AIMessage):\n",
    "                    ai_response = msg.content\n",
    "                    break\n",
    "        \n",
    "        if ai_response:\n",
    "            response = ai_response\n",
    "        else:\n",
    "            response = \"ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "        st.session_state.chat_history.append((\"assistant\", error_msg))\n",
    "    \n",
    "    finally:\n",
    "        # ì…ë ¥ì°½ ì´ˆê¸°í™” ë° ì²˜ë¦¬ ìƒíƒœ í•´ì œ\n",
    "        st.session_state.current_input = \"\"\n",
    "        st.session_state.processing = False\n",
    "\n",
    "# ============== ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ==============\n",
    "\n",
    "def handle_quick_summary():\n",
    "    \"\"\"íŒŒì¼ ìš”ì•½ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = summarize_content_tool_direct()\n",
    "        st.session_state.chat_history.append((\"user\", \"ì´ íŒŒì¼ì„ ìš”ì•½í•´ì¤˜\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"ìš”ì•½ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_info():\n",
    "    \"\"\"íŒŒì¼ ì •ë³´ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = get_document_info_tool_direct()\n",
    "        st.session_state.chat_history.append((\"user\", \"íŒŒì¼ ì •ë³´ë¥¼ ì•Œë ¤ì¤˜\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_search():\n",
    "    \"\"\"í‚¤ì›Œë“œ ê²€ìƒ‰ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = search_uploaded_documents_direct(\"ì¤‘ìš”í•œ í‚¤ì›Œë“œ\")\n",
    "        st.session_state.chat_history.append((\"user\", \"íŒŒì¼ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ì¤˜\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_file_search():\n",
    "    \"\"\"íŒŒì¼ ë‚´ ê²€ìƒ‰ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = \"ì–´ë–¤ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\"\n",
    "        st.session_state.chat_history.append((\"user\", \"íŒŒì¼ì—ì„œ íŠ¹ì • ë‚´ìš©ì„ ê²€ìƒ‰í•˜ê³  ì‹¶ì–´\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_python():\n",
    "    \"\"\"íŒŒì´ì¬ ì§ˆë¬¸ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = general_chat_tool_direct(\"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€?\")\n",
    "        st.session_state.chat_history.append((\"user\", \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€?\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_web_search():\n",
    "    \"\"\"ì›¹ ê²€ìƒ‰ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = web_search_tool_direct(\"ìµœì‹  AI ë‰´ìŠ¤\")\n",
    "        st.session_state.chat_history.append((\"user\", \"ìµœì‹  AI ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_ai_question():\n",
    "    \"\"\"AI ì§ˆë¬¸ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = general_chat_tool_direct(\"ChatGPTì™€ Claudeì˜ ì°¨ì´ì ì€?\")\n",
    "        st.session_state.chat_history.append((\"user\", \"ChatGPTì™€ Claudeì˜ ì°¨ì´ì ì€?\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_coding():\n",
    "    \"\"\"ì½”ë”© ì§ˆë¬¸ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = general_chat_tool_direct(\"íŒŒì´ì¬ í´ë˜ìŠ¤ì™€ ê°ì²´ì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì¤˜\")\n",
    "        st.session_state.chat_history.append((\"user\", \"íŒŒì´ì¬ í´ë˜ìŠ¤ì™€ ê°ì²´ì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì¤˜\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "# ============== Streamlit UI ==============\n",
    "\n",
    "def main():\n",
    "    st.title(\"ğŸ¤– íŒŒì¼ ë¶„ì„ AI ì–´ì‹œìŠ¤í„´íŠ¸\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # API í‚¤ ì²´í¬\n",
    "    if not os.getenv('OPENAI_API_KEY'):\n",
    "        st.error(\"âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        st.stop()\n",
    "    \n",
    "    # ì‚¬ì´ë“œë°”\n",
    "    with st.sidebar:\n",
    "        st.header(\"ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ\")\n",
    "        \n",
    "        # íŒŒì¼ ì—…ë¡œë“œ\n",
    "        uploaded_file = st.file_uploader(\n",
    "            \"íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”\",\n",
    "            type=['pdf', 'txt', 'md', 'py', 'js', 'html', 'css', 'json', 'xml', 'csv'],\n",
    "            help=\"PDF, í…ìŠ¤íŠ¸ íŒŒì¼, ì½”ë“œ íŒŒì¼ ë“±ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "        )\n",
    "        \n",
    "        if uploaded_file is not None:\n",
    "            st.info(f\"ğŸ“ ì„ íƒëœ íŒŒì¼: {uploaded_file.name}\")\n",
    "            st.info(f\"ğŸ“ íŒŒì¼ í¬ê¸°: {uploaded_file.size:,} bytes\")\n",
    "            \n",
    "            if st.button(\"ğŸ“Š íŒŒì¼ ë¶„ì„ ì‹œì‘\", type=\"primary\"):\n",
    "                with st.spinner(\"íŒŒì¼ì„ ë¶„ì„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...\"):\n",
    "                    try:\n",
    "                        # í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "                        full_text = extract_text_from_file(uploaded_file)\n",
    "                        \n",
    "                        if full_text:\n",
    "                            # ì²­í‚¹\n",
    "                            st.session_state.chunks = chunk_text(full_text)\n",
    "                            st.info(f\"âœ… ì²­í‚¹ ì™„ë£Œ! ì´ {len(st.session_state.chunks)}ê°œ ì²­í¬ ìƒì„±\")\n",
    "                            \n",
    "                            # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
    "                            index, embedding_model, metadatas = create_vectorstore(st.session_state.chunks)\n",
    "                            \n",
    "                            if index is not None:\n",
    "                                st.session_state.index = index\n",
    "                                st.session_state.embedding_model = embedding_model\n",
    "                                st.session_state.metadatas = metadatas\n",
    "                                st.session_state.file_processed = True\n",
    "                                st.session_state.uploaded_filename = uploaded_file.name\n",
    "                                \n",
    "                                st.success(\"ğŸ‰ íŒŒì¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "                                st.balloons()\n",
    "                    except Exception as e:\n",
    "                        st.error(f\"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "        # ë¬¸ì„œ ì •ë³´ í‘œì‹œ\n",
    "        if st.session_state.file_processed:\n",
    "            st.markdown(\"---\")\n",
    "            st.header(\"ğŸ“Š íŒŒì¼ ì •ë³´\")\n",
    "            \n",
    "            if hasattr(st.session_state, 'uploaded_filename'):\n",
    "                st.info(f\"ğŸ“ íŒŒì¼ëª…: {st.session_state.uploaded_filename}\")\n",
    "            \n",
    "            if st.session_state.chunks:\n",
    "                total_chars = sum(len(chunk) for chunk in st.session_state.chunks)\n",
    "                \n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    st.metric(\"ì²­í¬ ìˆ˜\", len(st.session_state.chunks))\n",
    "                with col2:\n",
    "                    st.metric(\"ì´ ê¸€ì ìˆ˜\", f\"{total_chars:,}\")\n",
    "            \n",
    "            # ì´ˆê¸°í™” ë²„íŠ¼\n",
    "            if st.button(\"ğŸ”„ ì´ˆê¸°í™”\", help=\"ì—…ë¡œë“œëœ íŒŒì¼ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤\"):\n",
    "                for key in ['chunks', 'index', 'embedding_model', 'metadatas', 'file_processed', 'chat_history', 'uploaded_filename', 'file_metadata', 'pdf_metadata', 'current_input', 'processing']:\n",
    "                    if key in st.session_state:\n",
    "                        del st.session_state[key]\n",
    "                st.rerun()\n",
    "    \n",
    "    # ë©”ì¸ ì½˜í…ì¸  - í•­ìƒ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ\n",
    "    st.header(\"ğŸ’¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì™€ ëŒ€í™”í•˜ê¸°\")\n",
    "    \n",
    "    if not st.session_state.file_processed:\n",
    "        st.info(\"ğŸ’¡ ì¼ë°˜ ì§ˆë¬¸ë„ ê°€ëŠ¥í•˜ê³ , íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ íŒŒì¼ ë¶„ì„ë„ í•  ìˆ˜ ìˆì–´ìš”!\")\n",
    "        \n",
    "        # ì‚¬ìš©ë²• ì•ˆë‚´\n",
    "        with st.expander(\"ğŸ“– ì‚¬ìš©ë²• ì•ˆë‚´\", expanded=False):\n",
    "            st.markdown(\"\"\"\n",
    "            ### ğŸš€ ë‘ ê°€ì§€ ì‚¬ìš© ë°©ë²•\n",
    "            \n",
    "            #### 1ï¸âƒ£ ì¼ë°˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ì‚¬ìš©\n",
    "            - ë°”ë¡œ ì•„ë˜ì—ì„œ ì§ˆë¬¸í•˜ì„¸ìš”!\n",
    "            - ì›¹ ê²€ìƒ‰, ì¼ë°˜ ì§€ì‹ ì§ˆë¬¸ ë“± ëª¨ë“  ì§ˆë¬¸ ê°€ëŠ¥\n",
    "            \n",
    "            #### 2ï¸âƒ£ íŒŒì¼ ë¶„ì„ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)\n",
    "            1. **íŒŒì¼ ì—…ë¡œë“œ**: ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”\n",
    "               - ğŸ“„ **PDF**: ë¬¸ì„œ, ë…¼ë¬¸, ë³´ê³ ì„œ ë“±\n",
    "               - ğŸ“ **í…ìŠ¤íŠ¸**: .txt, .md íŒŒì¼\n",
    "               - ğŸ’» **ì½”ë“œ**: .py, .js, .html, .css, .json ë“±\n",
    "               - ğŸ“Š **ë°ì´í„°**: .csv, .xml ë“±\n",
    "            2. **ë¶„ì„ ì‹œì‘**: \"íŒŒì¼ ë¶„ì„ ì‹œì‘\" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”\n",
    "            3. **íŒŒì¼ ì§ˆë¬¸**: ì—…ë¡œë“œí•œ íŒŒì¼ì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "            \n",
    "            ### ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸\n",
    "            **ì¼ë°˜ ì§ˆë¬¸:**\n",
    "            - \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€?\"\n",
    "            - \"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì–´ë•Œ?\"\n",
    "            - \"ìµœì‹  AI ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\"\n",
    "            \n",
    "            **íŒŒì¼ ì§ˆë¬¸ (ì—…ë¡œë“œ í›„):**\n",
    "            - \"ì´ íŒŒì¼ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜\"\n",
    "            - \"ì½”ë“œì—ì„œ í•¨ìˆ˜ë“¤ì„ ì„¤ëª…í•´ì¤˜\"\n",
    "            - \"íŒŒì¼ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ì¤˜\"\n",
    "            - \"ì´ ë°ì´í„°ì˜ íŒ¨í„´ì„ ë¶„ì„í•´ì¤˜\"\n",
    "            \"\"\")\n",
    "    \n",
    "    # ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì´ˆê¸°í™” (ëª¨ë“  tool í•¨ìˆ˜ê°€ ì •ì˜ëœ í›„ì— ì‹¤í–‰)\n",
    "    try:\n",
    "        if st.session_state.agent_graph is None:\n",
    "            st.session_state.agent_graph = graph\n",
    "    except Exception as e:\n",
    "        st.error(f\"AI ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        st.info(\"í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.\")\n",
    "    \n",
    "    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ\n",
    "    chat_container = st.container()\n",
    "    \n",
    "    with chat_container:\n",
    "        for i, (role, message) in enumerate(st.session_state.chat_history):\n",
    "            if role == \"user\":\n",
    "                with st.chat_message(\"user\"):\n",
    "                    st.write(message)\n",
    "            else:\n",
    "                with st.chat_message(\"assistant\"):\n",
    "                    st.write(message)\n",
    "    \n",
    "    # ì‚¬ìš©ì ì…ë ¥ (í•­ìƒ ë§¨ ì•„ë˜ì— ê³ ì •)\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"âœï¸ ì§ˆë¬¸í•˜ê¸°\")\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ ì…ë ¥ê³¼ ë²„íŠ¼ì„ ê°™ì€ í–‰ì— ë°°ì¹˜\n",
    "    col1, col2 = st.columns([4, 1])\n",
    "    \n",
    "    with col1:\n",
    "        # on_change ì½œë°±ì„ ì‚¬ìš©í•˜ì—¬ ì—”í„°í‚¤ ì²˜ë¦¬\n",
    "        user_input = st.text_input(\n",
    "            \"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\",\n",
    "            value=st.session_state.current_input,\n",
    "            placeholder=\"ì˜ˆ: 'íŒŒì´ì¬ì´ë€?' ë˜ëŠ” 'íŒŒì¼ì„ ìš”ì•½í•´ì¤˜' (Enter ë˜ëŠ” ì „ì†¡ ë²„íŠ¼)\",\n",
    "            key=\"text_input\",\n",
    "            on_change=process_user_input\n",
    "        )\n",
    "        # ì…ë ¥ê°’ì„ ì„¸ì…˜ ìƒíƒœì— ë™ê¸°í™”\n",
    "        st.session_state.current_input = user_input\n",
    "    \n",
    "    with col2:\n",
    "        # ì „ì†¡ ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬\n",
    "        if st.button(\"ì „ì†¡\", type=\"primary\", use_container_width=True):\n",
    "            process_user_input()\n",
    "            st.rerun()\n",
    "    \n",
    "    # ë¹ ë¥¸ ì§ˆë¬¸ ë²„íŠ¼ë“¤\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    if st.session_state.file_processed:\n",
    "        st.subheader(\"ğŸ¯ íŒŒì¼ ê´€ë ¨ ë¹ ë¥¸ ì§ˆë¬¸\")\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "        \n",
    "        with col1:\n",
    "            if st.button(\"ğŸ“ íŒŒì¼ ìš”ì•½\", on_click=handle_quick_summary):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col2:\n",
    "            if st.button(\"ğŸ“Š íŒŒì¼ ì •ë³´\", on_click=handle_quick_info):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col3:\n",
    "            if st.button(\"ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰\", on_click=handle_quick_search):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col4:\n",
    "            if st.button(\"ğŸ“„ íŒŒì¼ ë‚´ ê²€ìƒ‰\", on_click=handle_quick_file_search):\n",
    "                st.rerun()\n",
    "    \n",
    "    else:\n",
    "        st.subheader(\"ğŸ¯ ì¼ë°˜ ì§ˆë¬¸ ì˜ˆì‹œ\")\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "        \n",
    "        with col1:\n",
    "            if st.button(\"ğŸ íŒŒì´ì¬ ì§ˆë¬¸\", on_click=handle_quick_python):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col2:\n",
    "            if st.button(\"ğŸŒ ì›¹ ê²€ìƒ‰\", on_click=handle_quick_web_search):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col3:\n",
    "            if st.button(\"ğŸ¤– AI ì§ˆë¬¸\", on_click=handle_quick_ai_question):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col4:\n",
    "            if st.button(\"ğŸ’» ì½”ë”© ì§ˆë¬¸\", on_click=handle_quick_coding):\n",
    "                st.rerun()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "â€¢ \"ì´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜\"\n",
    "â€¢ \"íŠ¹ì • í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•´ì¤˜\"\n",
    "â€¢ \"ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ì°¾ì•„ì¤˜\"\n",
    "\"\"\"\n",
    "\n",
    "        return info_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "# ============== ì§ì ‘ í˜¸ì¶œ í•¨ìˆ˜ë“¤ (ë¹ ë¥¸ ë²„íŠ¼ìš©) ==============\n",
    "\n",
    "def search_uploaded_documents_direct(query: str, k: int = 3) -> str:\n",
    "    \"\"\"ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤. (ì§ì ‘ í˜¸ì¶œìš©)\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "        results = safe_search_documents(query, k)\n",
    "        \n",
    "        if not results:\n",
    "            return f\"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            formatted_results.append(\n",
    "                f\"[ê²€ìƒ‰ê²°ê³¼ {i}] (ìœ ì‚¬ë„: {result['score']:.3f})\\n\"\n",
    "                f\"{result['content'][:400]}{'...' if len(result['content']) > 400 else ''}\\n\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n\".join(formatted_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"íŒŒì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "def web_search_tool_direct(query: str) -> str:\n",
    "    \"\"\"ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. (ì§ì ‘ í˜¸ì¶œìš©)\"\"\"\n",
    "    try:\n",
    "        from langchain_community.tools import DuckDuckGoSearchRun\n",
    "        search_tool = DuckDuckGoSearchRun()\n",
    "        results = search_tool.run(query)\n",
    "        return f\"ğŸŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼:\\n\\n{results}\"\n",
    "    except ImportError:\n",
    "        return f\"\"\"ğŸ” \"{query}\" ê²€ìƒ‰ ë§í¬:\n",
    "â€¢ Google: https://www.google.com/search?q={query.replace(' ', '+')}\n",
    "â€¢ ë„¤ì´ë²„: https://search.naver.com/search.naver?query={query.replace(' ', '+')}\n",
    "\n",
    "ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰: pip install duckduckgo-search\"\"\"\n",
    "    except Exception as e:\n",
    "        return f\"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "def general_chat_tool_direct(question: str) -> str:\n",
    "    \"\"\"ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤. (ì§ì ‘ í˜¸ì¶œìš©)\"\"\"\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "        response = llm.invoke([HumanMessage(content=question)])\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "def summarize_content_tool_direct(content: str = \"\", style: str = \"general\") -> str:\n",
    "    \"\"\"ì£¼ì–´ì§„ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤. (ì§ì ‘ í˜¸ì¶œìš©)\"\"\"\n",
    "    try:\n",
    "        # contentê°€ ë¹„ì–´ìˆìœ¼ë©´ ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš©\n",
    "        if not content.strip():\n",
    "            if (not hasattr(st.session_state, 'file_processed') or \n",
    "                not st.session_state.file_processed or\n",
    "                not hasattr(st.session_state, 'chunks') or\n",
    "                not st.session_state.chunks):\n",
    "                return \"ìš”ì•½í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\"\n",
    "            \n",
    "            # ì²˜ìŒ 5ê°œ ì²­í¬ë¥¼ ìš”ì•½ (ë” ë§ì€ ë‚´ìš©)\n",
    "            content = \"\\n\".join(st.session_state.chunks[:5])\n",
    "        \n",
    "        if not content.strip():\n",
    "            return \"ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì²˜ë¦¬\n",
    "        if len(content) > 8000:\n",
    "            content = content[:8000] + \"...\"\n",
    "        \n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "        \n",
    "        # ê°„ë‹¨í•œ ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "        prompt = f\"\"\"ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "{content}\n",
    "\n",
    "ìš”ì•½:\"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        return response.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "def get_document_info_tool_direct() -> str:\n",
    "    \"\"\"í˜„ì¬ ë¡œë“œëœ íŒŒì¼ì˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ì§ì ‘ í˜¸ì¶œìš©)\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "        if not hasattr(st.session_state, 'chunks') or not st.session_state.chunks:\n",
    "            return \"íŒŒì¼ ì²˜ë¦¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # ê¸°ë³¸ í†µê³„ ì •ë³´\n",
    "        total_chars = sum(len(chunk) for chunk in st.session_state.chunks)\n",
    "        filename = getattr(st.session_state, 'uploaded_filename', 'ì•Œ ìˆ˜ ì—†ìŒ')\n",
    "        \n",
    "        # íŒŒì¼ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "        file_meta = getattr(st.session_state, 'file_metadata', {})\n",
    "        pdf_meta = getattr(st.session_state, 'pdf_metadata', {})\n",
    "        \n",
    "        info_text = f\"\"\"ğŸ“„ **íŒŒì¼ ì •ë³´**\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "ğŸ“ **ê¸°ë³¸ ì •ë³´**\n",
    "â€¢ íŒŒì¼ëª…: {filename}\n",
    "â€¢ íŒŒì¼ í˜•ì‹: {file_meta.get('file_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "â€¢ íŒŒì¼ í¬ê¸°: {file_meta.get('file_size_mb', 0)} MB ({file_meta.get('file_size', 0):,} bytes)\n",
    "\"\"\"\n",
    "\n",
    "        # PDF ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°\n",
    "        if pdf_meta:\n",
    "            info_text += f\"\"\"\n",
    "ğŸ“– **PDF ë¬¸ì„œ ì •ë³´**\n",
    "â€¢ ì œëª©: {pdf_meta.get('title', 'ì œëª© ì—†ìŒ')}\n",
    "â€¢ ì‘ì„±ì: {pdf_meta.get('author', 'ì‘ì„±ì ì—†ìŒ')}\n",
    "â€¢ ì£¼ì œ: {pdf_meta.get('subject', 'ì£¼ì œ ì—†ìŒ')}\n",
    "â€¢ ì´ í˜ì´ì§€ ìˆ˜: {pdf_meta.get('total_pages', 'ì•Œ ìˆ˜ ì—†ìŒ')}í˜ì´ì§€\n",
    "â€¢ ìƒì„± í”„ë¡œê·¸ë¨: {pdf_meta.get('creator', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "â€¢ ì œì‘ í”„ë¡œê·¸ë¨: {pdf_meta.get('producer', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "â€¢ ìƒì„±ì¼: {pdf_meta.get('creationDate', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "â€¢ ìˆ˜ì •ì¼: {pdf_meta.get('modDate', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "\"\"\"\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ íŒŒì¼ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°\n",
    "        if 'lines' in file_meta:\n",
    "            info_text += f\"\"\"\n",
    "ğŸ“ **{file_meta.get('file_type_name', 'í…ìŠ¤íŠ¸ íŒŒì¼')} ì •ë³´**\n",
    "â€¢ íŒŒì¼ í˜•ì‹: {file_meta.get('extension', 'TXT')} íŒŒì¼\n",
    "â€¢ ì¸ì½”ë”©: {file_meta.get('encoding', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
    "â€¢ ì´ ì¤„ ìˆ˜: {file_meta.get('lines', 0):,}ì¤„\n",
    "â€¢ ì´ ë‹¨ì–´ ìˆ˜: {file_meta.get('words', 0):,}ê°œ\n",
    "â€¢ ì´ ë¬¸ì ìˆ˜: {file_meta.get('characters', 0):,}ì\n",
    "â€¢ ë‚´ìš©ì´ ìˆëŠ” ì¤„: {file_meta.get('paragraphs', 0):,}ì¤„\n",
    "â€¢ ë¹ˆ ì¤„: {file_meta.get('empty_lines', 0):,}ì¤„\n",
    "\"\"\"\n",
    "\n",
    "        info_text += f\"\"\"\n",
    "ğŸ”§ **ë¶„ì„ ì •ë³´**\n",
    "â€¢ ì²­í¬ ìˆ˜: {len(st.session_state.chunks):,}ê°œ\n",
    "â€¢ ì´ í…ìŠ¤íŠ¸ ê¸¸ì´: {total_chars:,}ì\n",
    "â€¢ í‰ê·  ì²­í¬ í¬ê¸°: {total_chars // len(st.session_state.chunks):,}ì\n",
    "\n",
    "ğŸ› ï¸ **ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥**\n",
    "â€¢ ğŸ“ íŒŒì¼ ë‚´ìš© ìš”ì•½\n",
    "â€¢ ğŸ” í‚¤ì›Œë“œ/ë‚´ìš© ê²€ìƒ‰  \n",
    "â€¢ ğŸŒ ì›¹ ê²€ìƒ‰ê³¼ ë¹„êµ\n",
    "â€¢ ğŸ’¬ íŒŒì¼ ê´€ë ¨ ì§ˆì˜ì‘ë‹µ\n",
    "\n",
    "ğŸ’¡ **ì˜ˆì‹œ ì§ˆë¬¸**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e26deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== ì§ì ‘ í˜¸ì¶œ í•¨ìˆ˜ë“¤ (tool ë°ì½”ë ˆì´í„° ì œê±°) ==============\n",
    "\n",
    "@tool\n",
    "def search_uploaded_documents_direct(query: str, k: int = 3) -> str:\n",
    "    \"\"\"ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "        results = safe_search_documents(query, k)\n",
    "        \n",
    "        if not results:\n",
    "            return f\"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            formatted_results.append(\n",
    "                f\"[ê²€ìƒ‰ê²°ê³¼ {i}] (ìœ ì‚¬ë„: {result['score']:.3f})\\n\"\n",
    "                f\"{result['content'][:400]}{'...' if len(result['content']) > 400 else ''}\\n\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n\".join(formatted_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"íŒŒì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def web_search_tool_direct(query: str) -> str:\n",
    "    \"\"\"ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        from langchain_community.tools import DuckDuckGoSearchRun\n",
    "        search_tool = DuckDuckGoSearchRun()\n",
    "        results = search_tool.run(query)\n",
    "        return f\"ğŸŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼:\\n\\n{results}\"\n",
    "    except ImportError:\n",
    "        return f\"\"\"ğŸ” \"{query}\" ê²€ìƒ‰ ë§í¬:\n",
    "â€¢ Google: https://www.google.com/search?q={query.replace(' ', '+')}\n",
    "â€¢ ë„¤ì´ë²„: https://search.naver.com/search.naver?query={query.replace(' ', '+')}\n",
    "\n",
    "ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰: pip install duckduckgo-search\"\"\"\n",
    "    except Exception as e:\n",
    "        return f\"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def general_chat_tool_direct(question: str) -> str:\n",
    "    \"\"\"ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "        response = llm.invoke([HumanMessage(content=question)])\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def summarize_content_tool_direct(content: str = \"\", style: str = \"general\") -> str:\n",
    "    \"\"\"ì£¼ì–´ì§„ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        # contentê°€ ë¹„ì–´ìˆìœ¼ë©´ ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš©\n",
    "        if not content.strip():\n",
    "            if (not hasattr(st.session_state, 'file_processed') or \n",
    "                not st.session_state.file_processed or\n",
    "                not hasattr(st.session_state, 'chunks') or\n",
    "                not st.session_state.chunks):\n",
    "                return \"ìš”ì•½í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\"\n",
    "            \n",
    "            # ì²˜ìŒ 5ê°œ ì²­í¬ë¥¼ ìš”ì•½ (ë” ë§ì€ ë‚´ìš©)\n",
    "            content = \"\\n\".join(st.session_state.chunks[:5])\n",
    "        \n",
    "        if not content.strip():\n",
    "            return \"ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì²˜ë¦¬\n",
    "        if len(content) > 8000:\n",
    "            content = content[:8000] + \"...\"\n",
    "        \n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "        \n",
    "        # ê°„ë‹¨í•œ ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "        prompt = f\"\"\"ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "{content}\n",
    "\n",
    "ìš”ì•½:\"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        return response.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_document_info_tool_direct() -> str:\n",
    "    \"\"\"í˜„ì¬ ë¡œë“œëœ íŒŒì¼ì˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "        if not hasattr(st.session_state, 'chunks') or not st.session_state.chunks:\n",
    "            return \"íŒŒì¼ ì²˜ë¦¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        total_chars = sum(len(chunk) for chunk in st.session_state.chunks)\n",
    "        filename = getattr(st.session_state, 'uploaded_filename', 'ì•Œ ìˆ˜ ì—†ìŒ')\n",
    "        \n",
    "        return f\"\"\"ğŸ“„ í˜„ì¬ ë¡œë“œëœ íŒŒì¼ ì •ë³´:\n",
    "- íŒŒì¼ëª…: {filename}\n",
    "- ì´ ì²­í¬ ìˆ˜: {len(st.session_state.chunks)}\n",
    "- ì´ ê¸€ì ìˆ˜: {total_chars:,}\n",
    "- í‰ê·  ì²­í¬ í¬ê¸°: {total_chars // len(st.session_state.chunks):,} ê¸€ì\n",
    "\n",
    "ğŸ› ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ë“¤:\n",
    "- íŒŒì¼ ë‚´ìš© ê²€ìƒ‰\n",
    "- ì›¹ì—ì„œ ìµœì‹  ì •ë³´ ê²€ìƒ‰\n",
    "- ë‚´ìš© ìš”ì•½\n",
    "- íŒŒì¼ ì •ë³´ ì¡°íšŒ\n",
    "\n",
    "ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸: \"íŒŒì¼ì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ì°¾ì•„ì¤˜\", \"íŒŒì¼ì„ ìš”ì•½í•´ì¤˜\" \"\"\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d8747be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_list = [search_uploaded_documents_direct, web_search_tool_direct, general_chat_tool_direct, summarize_content_tool_direct, get_document_info_tool_direct ]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tool_list)\n",
    "tool_node = ToolNode(tool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddd20ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return END\n",
    "\n",
    "def agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"LLM ëª¨ë¸ í˜¸ì¶œ\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ì‚¬ìš©ì ë©”ì‹œì§€ì¸ì§€ í™•ì¸\n",
    "    if not messages or not isinstance(messages[-1], HumanMessage):\n",
    "        return state\n",
    "    \n",
    "    user_message = messages[-1].content\n",
    "    \n",
    "    try:\n",
    "        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¼ìš°íŒ…\n",
    "        user_lower = user_message.lower()\n",
    "        \n",
    "        # íŒŒì¼ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€\n",
    "        file_keywords = ['íŒŒì¼', 'ë¬¸ì„œ', 'ìš”ì•½', 'ê²€ìƒ‰', 'ì •ë³´', 'ë‚´ìš©']\n",
    "        is_file_related = any(keyword in user_lower for keyword in file_keywords)\n",
    "        \n",
    "        # ì›¹ ê²€ìƒ‰ í‚¤ì›Œë“œ ê°ì§€\n",
    "        web_keywords = ['ê²€ìƒ‰', 'ë‰´ìŠ¤', 'ìµœì‹ ', 'ë‚ ì”¨', 'í˜„ì¬']\n",
    "        needs_web_search = any(keyword in user_lower for keyword in web_keywords)\n",
    "        \n",
    "        response_content = \"\"\n",
    "        \n",
    "        if is_file_related and st.session_state.file_processed:\n",
    "            # íŒŒì¼ ê´€ë ¨ ì²˜ë¦¬\n",
    "            if 'ìš”ì•½' in user_lower:\n",
    "                response_content = summarize_content_tool_direct()\n",
    "            elif 'ì •ë³´' in user_lower:\n",
    "                response_content = get_document_info_tool_direct()\n",
    "            else:\n",
    "                response_content = search_uploaded_documents_direct(user_message)\n",
    "        \n",
    "        elif needs_web_search:\n",
    "            # ì›¹ ê²€ìƒ‰ ì²˜ë¦¬\n",
    "            response_content = web_search_tool_direct(user_message)\n",
    "        \n",
    "        else:\n",
    "            # ì¼ë°˜ ì±„íŒ… ì²˜ë¦¬\n",
    "            response_content = general_chat_tool_direct(user_message)\n",
    "        \n",
    "        # AI ì‘ë‹µ ìƒì„±\n",
    "        ai_response = AIMessage(content=response_content)\n",
    "        return {\"messages\": messages + [ai_response]}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_response = AIMessage(content=f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")\n",
    "        return {\"messages\": messages + [error_response]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ecd960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 14:14:22.849 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000118F99CDE10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  langgraph.graph import START, END\n",
    "graph_builder = StateGraph(AgentState)\n",
    "graph_builder.add_node('agent', agent)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "graph_builder.add_conditional_edges(\n",
    "    'agent',\n",
    "    should_continue,\n",
    "    ['tools', END]\n",
    ")\n",
    "graph_builder.add_edge('tools', 'agent')\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da1ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
