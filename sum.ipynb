{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe55bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import fitz  # pymupdf\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict, List, Dict, Any\n",
    "import pickle\n",
    "import os\n",
    "import tempfile\n",
    "from dotenv import load_dotenv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e5d39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 14:11:28.085 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "st.set_page_config(\n",
    "    page_title=\"PDF 분석 AI 어시스턴트\",\n",
    "    page_icon=\"🤖\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70321de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f329ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o', streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "722e9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_session_state():\n",
    "    \"\"\"세션 상태 안전하게 초기화\"\"\"\n",
    "    if 'chunks' not in st.session_state:\n",
    "        st.session_state.chunks = []\n",
    "    if 'index' not in st.session_state:\n",
    "        st.session_state.index = None\n",
    "    if 'embedding_model' not in st.session_state:\n",
    "        st.session_state.embedding_model = None\n",
    "    if 'metadatas' not in st.session_state:\n",
    "        st.session_state.metadatas = []\n",
    "    if 'file_processed' not in st.session_state:\n",
    "        st.session_state.file_processed = False\n",
    "    if 'chat_history' not in st.session_state:\n",
    "        st.session_state.chat_history = []\n",
    "    if 'agent_graph' not in st.session_state:\n",
    "        st.session_state.agent_graph = None\n",
    "    if 'uploaded_filename' not in st.session_state:\n",
    "        st.session_state.uploaded_filename = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9277e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 14:11:28.710 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.710 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.710 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-20 14:11:28.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "init_session_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2acea5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: List[Any]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== PDF 분석 Streamlit 앱 ==============\n",
    "import streamlit as st\n",
    "import fitz  # pymupdf\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict, List, Dict, Any\n",
    "import pickle\n",
    "import os\n",
    "import tempfile\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# 페이지 설정\n",
    "st.set_page_config(\n",
    "    page_title=\"파일 분석 AI 어시스턴트\",\n",
    "    page_icon=\"🤖\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# 환경 설정\n",
    "load_dotenv()\n",
    "\n",
    "# ============== 세션 상태 초기화 ==============\n",
    "def init_session_state():\n",
    "    \"\"\"세션 상태 안전하게 초기화\"\"\"\n",
    "    if 'chunks' not in st.session_state:\n",
    "        st.session_state.chunks = []\n",
    "    if 'index' not in st.session_state:\n",
    "        st.session_state.index = None\n",
    "    if 'embedding_model' not in st.session_state:\n",
    "        st.session_state.embedding_model = None\n",
    "    if 'metadatas' not in st.session_state:\n",
    "        st.session_state.metadatas = []\n",
    "    if 'file_processed' not in st.session_state:\n",
    "        st.session_state.file_processed = False\n",
    "    if 'chat_history' not in st.session_state:\n",
    "        st.session_state.chat_history = []\n",
    "    if 'agent_graph' not in st.session_state:\n",
    "        st.session_state.agent_graph = None\n",
    "    if 'uploaded_filename' not in st.session_state:\n",
    "        st.session_state.uploaded_filename = \"\"\n",
    "    if 'file_metadata' not in st.session_state:\n",
    "        st.session_state.file_metadata = {}\n",
    "    if 'pdf_metadata' not in st.session_state:\n",
    "        st.session_state.pdf_metadata = {}\n",
    "    if 'current_input' not in st.session_state:\n",
    "        st.session_state.current_input = \"\"\n",
    "    if 'processing' not in st.session_state:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "# 초기화 실행\n",
    "init_session_state()\n",
    "\n",
    "# ============== 타입 정의 ==============\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[Any]\n",
    "\n",
    "# ============== 파일 처리 함수들 ==============\n",
    "\n",
    "def extract_text_from_file(uploaded_file):\n",
    "    \"\"\"다양한 파일 형식에서 텍스트 추출\"\"\"\n",
    "    file_type = uploaded_file.type\n",
    "    file_name = uploaded_file.name.lower()\n",
    "    \n",
    "    # 기본 파일 정보 저장\n",
    "    st.session_state.file_metadata = {\n",
    "        'filename': uploaded_file.name,\n",
    "        'file_type': file_type,\n",
    "        'file_size': uploaded_file.size,\n",
    "        'file_size_mb': round(uploaded_file.size / (1024*1024), 2)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if file_type == \"application/pdf\" or file_name.endswith('.pdf'):\n",
    "            return extract_text_with_fitz(uploaded_file)\n",
    "        \n",
    "        elif file_type == \"text/plain\" or file_name.endswith(('.txt', '.md', '.py', '.js', '.html', '.css', '.json', '.xml', '.csv')):\n",
    "            # 텍스트 파일 처리\n",
    "            content = uploaded_file.read()\n",
    "            if isinstance(content, bytes):\n",
    "                # 다양한 인코딩 시도\n",
    "                for encoding in ['utf-8', 'cp949', 'euc-kr', 'latin-1']:\n",
    "                    try:\n",
    "                        text = content.decode(encoding)\n",
    "                        st.success(f\"✅ 텍스트 파일 읽기 완료! ({encoding} 인코딩)\")\n",
    "                        \n",
    "                        # 텍스트 파일 상세 메타데이터 추가\n",
    "                        lines = text.split('\\n')\n",
    "                        words = text.split()\n",
    "                        \n",
    "                        # 파일 확장자로 파일 유형 판단\n",
    "                        file_ext = file_name.split('.')[-1] if '.' in file_name else 'txt'\n",
    "                        file_type_name = {\n",
    "                            'py': 'Python 코드',\n",
    "                            'js': 'JavaScript 코드', \n",
    "                            'html': 'HTML 문서',\n",
    "                            'css': 'CSS 스타일시트',\n",
    "                            'json': 'JSON 데이터',\n",
    "                            'xml': 'XML 문서',\n",
    "                            'csv': 'CSV 데이터',\n",
    "                            'md': 'Markdown 문서',\n",
    "                            'txt': '텍스트 문서'\n",
    "                        }.get(file_ext, '텍스트 파일')\n",
    "                        \n",
    "                        st.session_state.file_metadata.update({\n",
    "                            'encoding': encoding,\n",
    "                            'lines': len(lines),\n",
    "                            'words': len(words),\n",
    "                            'characters': len(text),\n",
    "                            'file_type_name': file_type_name,\n",
    "                            'extension': file_ext.upper(),\n",
    "                            'paragraphs': len([line for line in lines if line.strip()]),\n",
    "                            'empty_lines': len([line for line in lines if not line.strip()])\n",
    "                        })\n",
    "                        \n",
    "                        return text\n",
    "                    except UnicodeDecodeError:\n",
    "                        continue\n",
    "                st.error(\"❌ 텍스트 파일 인코딩을 인식할 수 없습니다.\")\n",
    "                return \"\"\n",
    "            else:\n",
    "                return str(content)\n",
    "        \n",
    "        else:\n",
    "            st.error(f\"❌ 지원하지 않는 파일 형식입니다: {file_type}\")\n",
    "            return \"\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        st.error(f\"❌ 파일 처리 중 오류: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_with_fitz(pdf_file):\n",
    "    \"\"\"PyMuPDF로 PDF 텍스트 추출\"\"\"\n",
    "    try:\n",
    "        # 임시 파일로 저장\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:\n",
    "            tmp_file.write(pdf_file.read())\n",
    "            tmp_path = tmp_file.name\n",
    "        \n",
    "        doc = fitz.open(tmp_path)\n",
    "        \n",
    "        # PDF 메타데이터 추출\n",
    "        metadata = doc.metadata\n",
    "        st.session_state.pdf_metadata = {\n",
    "            'title': metadata.get('title', '제목 없음'),\n",
    "            'author': metadata.get('author', '작성자 없음'),\n",
    "            'subject': metadata.get('subject', '주제 없음'),\n",
    "            'creator': metadata.get('creator', '생성 프로그램 없음'),\n",
    "            'producer': metadata.get('producer', '제작 프로그램 없음'),\n",
    "            'creationDate': metadata.get('creationDate', '생성일 없음'),\n",
    "            'modDate': metadata.get('modDate', '수정일 없음'),\n",
    "            'total_pages': len(doc)\n",
    "        }\n",
    "        \n",
    "        # 진행 상황 표시\n",
    "        progress_bar = st.progress(0)\n",
    "        status_text = st.empty()\n",
    "        \n",
    "        full_text = \"\"\n",
    "        total_pages = len(doc)\n",
    "        \n",
    "        for page_num in range(total_pages):\n",
    "            progress = (page_num + 1) / total_pages\n",
    "            progress_bar.progress(progress)\n",
    "            status_text.text(f\"페이지 {page_num + 1}/{total_pages} 처리 중...\")\n",
    "            \n",
    "            page = doc[page_num]\n",
    "            text = page.get_text()\n",
    "            \n",
    "            if text and text.strip():\n",
    "                text = text.replace('\\x00', '')\n",
    "                text = text.replace('\\ufeff', '')\n",
    "                text = text.replace('\\r\\n', '\\n')\n",
    "                text = text.replace('\\r', '\\n')\n",
    "                full_text += text + \"\\n\\n\"\n",
    "        \n",
    "        doc.close()\n",
    "        os.unlink(tmp_path)  # 임시 파일 삭제\n",
    "        \n",
    "        progress_bar.progress(1.0)\n",
    "        status_text.text(f\"✅ PDF 텍스트 추출 완료! 총 {len(full_text)} 글자\")\n",
    "        time.sleep(1)\n",
    "        progress_bar.empty()\n",
    "        status_text.empty()\n",
    "        \n",
    "        return full_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"❌ PDF 텍스트 추출 오류: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def chunk_text(text, chunk_size=2000, overlap=100):\n",
    "    \"\"\"텍스트를 청크로 나누는 함수\"\"\"\n",
    "    if not text.strip():\n",
    "        return []\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end].strip()\n",
    "        \n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        start = end - overlap\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def create_vectorstore(chunks):\n",
    "    \"\"\"FAISS 벡터 스토어 생성\"\"\"\n",
    "    if not chunks:\n",
    "        return None, None, None\n",
    "    \n",
    "    try:\n",
    "        with st.spinner('🔄 임베딩 생성 중... (시간이 걸릴 수 있습니다)'):\n",
    "            embedding_model = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "            embeddings = embedding_model.embed_documents(chunks)\n",
    "            embeddings = np.array(embeddings).astype('float32')\n",
    "            \n",
    "            # FAISS 인덱스 생성\n",
    "            dimension = embeddings.shape[1]\n",
    "            index = faiss.IndexFlatL2(dimension)\n",
    "            index.add(embeddings)\n",
    "            \n",
    "            # 메타데이터 생성\n",
    "            metadatas = []\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                metadatas.append({\n",
    "                    'chunk_id': i,\n",
    "                    'chunk_size': len(chunk),\n",
    "                    'preview': chunk[:100] + \"...\" if len(chunk) > 100 else chunk\n",
    "                })\n",
    "        \n",
    "        st.success(f\"✅ 벡터 스토어 생성 완료! {index.ntotal}개 벡터 저장\")\n",
    "        return index, embedding_model, metadatas\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"❌ 벡터 스토어 생성 오류: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def safe_search_documents(query, k=3):\n",
    "    \"\"\"안전한 문서 검색\"\"\"\n",
    "    try:\n",
    "        if (not hasattr(st.session_state, 'index') or \n",
    "            st.session_state.index is None or \n",
    "            not hasattr(st.session_state, 'embedding_model') or\n",
    "            st.session_state.embedding_model is None):\n",
    "            return []\n",
    "        \n",
    "        query_embedding = st.session_state.embedding_model.embed_query(query)\n",
    "        query_embedding = np.array([query_embedding]).astype('float32')\n",
    "        \n",
    "        distances, indices = st.session_state.index.search(query_embedding, k)\n",
    "        \n",
    "        results = []\n",
    "        for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "            if idx < len(st.session_state.chunks):\n",
    "                results.append({\n",
    "                    'chunk_id': idx,\n",
    "                    'content': st.session_state.chunks[idx],\n",
    "                    'score': 1.0 - (distance / 2.0),\n",
    "                    'metadata': st.session_state.metadatas[idx] if idx < len(st.session_state.metadatas) else {}\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"검색 오류: {e}\")\n",
    "        return []\n",
    "\n",
    "# ============== LangGraph Tools ==============\n",
    "\n",
    "@tool\n",
    "def search_uploaded_documents(query: str) -> str:\n",
    "    \"\"\"업로드된 파일에서 내용을 검색합니다.\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"업로드된 파일이 없습니다. 먼저 파일을 업로드하고 처리해주세요.\"\n",
    "        \n",
    "        results = safe_search_documents(query, 3)\n",
    "        \n",
    "        if not results:\n",
    "            return f\"'{query}'에 대한 검색 결과가 없습니다.\"\n",
    "        \n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            formatted_results.append(\n",
    "                f\"[검색결과 {i}] (유사도: {result['score']:.3f})\\n\"\n",
    "                f\"{result['content'][:400]}{'...' if len(result['content']) > 400 else ''}\\n\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n\".join(formatted_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"파일 검색 중 오류: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def web_search_tool(query: str) -> str:\n",
    "    \"\"\"웹에서 최신 정보를 검색합니다.\"\"\"\n",
    "    try:\n",
    "        from langchain_community.tools import DuckDuckGoSearchRun\n",
    "        search_tool = DuckDuckGoSearchRun()\n",
    "        results = search_tool.run(query)\n",
    "        return f\"🌐 웹 검색 결과:\\n\\n{results}\"\n",
    "    except ImportError:\n",
    "        return f\"\"\"🔍 \"{query}\" 검색 링크:\n",
    "• Google: https://www.google.com/search?q={query.replace(' ', '+')}\n",
    "• 네이버: https://search.naver.com/search.naver?query={query.replace(' ', '+')}\n",
    "\n",
    "실시간 웹 검색: pip install duckduckgo-search\"\"\"\n",
    "    except Exception as e:\n",
    "        return f\"웹 검색 중 오류: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def general_chat_tool(question: str) -> str:\n",
    "    \"\"\"일반적인 질문에 답변합니다.\"\"\"\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "        response = llm.invoke([HumanMessage(content=question)])\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"일반 질문 처리 중 오류: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def summarize_content_tool() -> str:\n",
    "    \"\"\"업로드된 파일의 내용을 요약합니다.\"\"\"\n",
    "    try:\n",
    "        if (not hasattr(st.session_state, 'file_processed') or \n",
    "            not st.session_state.file_processed or\n",
    "            not hasattr(st.session_state, 'chunks') or\n",
    "            not st.session_state.chunks):\n",
    "            return \"요약할 파일이 없습니다. 먼저 파일을 업로드하고 처리해주세요.\"\n",
    "        \n",
    "        # 처음 5개 청크를 요약 (더 많은 내용)\n",
    "        content = \"\\n\".join(st.session_state.chunks[:5])\n",
    "        \n",
    "        if not content.strip():\n",
    "            return \"요약할 내용이 없습니다.\"\n",
    "        \n",
    "        # 내용이 너무 길면 잘라서 처리\n",
    "        if len(content) > 8000:\n",
    "            content = content[:8000] + \"...\"\n",
    "        \n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "        \n",
    "        # 간단한 요약 프롬프트\n",
    "        prompt = f\"\"\"다음 내용을 한국어로 간단하고 명확하게 요약해주세요:\n",
    "\n",
    "{content}\n",
    "\n",
    "요약:\"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        return response.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"요약 중 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_document_info_tool() -> str:\n",
    "    \"\"\"현재 로드된 파일의 정보를 반환합니다.\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"로드된 파일이 없습니다. 파일을 먼저 업로드하고 처리해주세요.\"\n",
    "        \n",
    "        if not hasattr(st.session_state, 'chunks') or not st.session_state.chunks:\n",
    "            return \"파일 처리 정보가 없습니다.\"\n",
    "        \n",
    "        # 기본 통계 정보\n",
    "        total_chars = sum(len(chunk) for chunk in st.session_state.chunks)\n",
    "        filename = getattr(st.session_state, 'uploaded_filename', '알 수 없음')\n",
    "        \n",
    "        # 파일 메타데이터 가져오기\n",
    "        file_meta = getattr(st.session_state, 'file_metadata', {})\n",
    "        pdf_meta = getattr(st.session_state, 'pdf_metadata', {})\n",
    "        \n",
    "        info_text = f\"\"\"📄 **파일 정보**\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "📁 **기본 정보**\n",
    "• 파일명: {filename}\n",
    "• 파일 형식: {file_meta.get('file_type', '알 수 없음')}\n",
    "• 파일 크기: {file_meta.get('file_size_mb', 0)} MB ({file_meta.get('file_size', 0):,} bytes)\n",
    "\"\"\"\n",
    "\n",
    "        # PDF 메타데이터가 있는 경우\n",
    "        if pdf_meta:\n",
    "            info_text += f\"\"\"\n",
    "📖 **PDF 문서 정보**\n",
    "• 제목: {pdf_meta.get('title', '제목 없음')}\n",
    "• 작성자: {pdf_meta.get('author', '작성자 없음')}\n",
    "• 주제: {pdf_meta.get('subject', '주제 없음')}\n",
    "• 총 페이지 수: {pdf_meta.get('total_pages', '알 수 없음')}페이지\n",
    "• 생성 프로그램: {pdf_meta.get('creator', '알 수 없음')}\n",
    "• 제작 프로그램: {pdf_meta.get('producer', '알 수 없음')}\n",
    "• 생성일: {pdf_meta.get('creationDate', '알 수 없음')}\n",
    "• 수정일: {pdf_meta.get('modDate', '알 수 없음')}\n",
    "\"\"\"\n",
    "\n",
    "        # 텍스트 파일 메타데이터가 있는 경우\n",
    "        if 'lines' in file_meta:\n",
    "            info_text += f\"\"\"\n",
    "📝 **{file_meta.get('file_type_name', '텍스트 파일')} 정보**\n",
    "• 파일 형식: {file_meta.get('extension', 'TXT')} 파일\n",
    "• 인코딩: {file_meta.get('encoding', '알 수 없음')}\n",
    "• 총 줄 수: {file_meta.get('lines', 0):,}줄\n",
    "• 총 단어 수: {file_meta.get('words', 0):,}개\n",
    "• 총 문자 수: {file_meta.get('characters', 0):,}자\n",
    "• 내용이 있는 줄: {file_meta.get('paragraphs', 0):,}줄\n",
    "• 빈 줄: {file_meta.get('empty_lines', 0):,}줄\n",
    "\"\"\"\n",
    "\n",
    "        info_text += f\"\"\"\n",
    "🔧 **분석 정보**\n",
    "• 청크 수: {len(st.session_state.chunks):,}개\n",
    "• 총 텍스트 길이: {total_chars:,}자\n",
    "• 평균 청크 크기: {total_chars // len(st.session_state.chunks):,}자\n",
    "\n",
    "🛠️ **사용 가능한 기능**\n",
    "• 📝 파일 내용 요약\n",
    "• 🔍 키워드/내용 검색  \n",
    "• 🌐 웹 검색과 비교\n",
    "• 💬 파일 관련 질의응답\n",
    "\n",
    "💡 **예시 질문**\n",
    "• \"이 문서의 핵심 내용을 요약해줘\"\n",
    "• \"특정 키워드를 검색해줘\"\n",
    "• \"문서에서 중요한 부분을 찾아줘\"\n",
    "\"\"\"\n",
    "\n",
    "        return info_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"파일 정보 조회 중 오류: {str(e)}\"\n",
    "\n",
    "# ============== LangGraph 그래프 ==============\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"다음 단계를 결정하는 함수 - tool calling 제거로 항상 END\"\"\"\n",
    "    return END\n",
    "\n",
    "def agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"LLM 에이전트 함수 - 키워드 기반 라우팅으로 tool calling 에러 방지\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # 메시지가 비어있으면 기본 응답\n",
    "    if not messages:\n",
    "        return {\"messages\": [AIMessage(content=\"안녕하세요! 무엇을 도와드릴까요?\")]}\n",
    "    \n",
    "    # 마지막 사용자 메시지 가져오기\n",
    "    user_message = \"\"\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            user_message = msg.content\n",
    "            break\n",
    "    \n",
    "    if not user_message:\n",
    "        return {\"messages\": messages + [AIMessage(content=\"질문을 입력해주세요.\")]}\n",
    "    \n",
    "    try:\n",
    "        # 키워드 기반 라우팅으로 tool calling 대신 직접 함수 호출\n",
    "        user_lower = user_message.lower()\n",
    "        \n",
    "        # 파일 관련 키워드\n",
    "        file_keywords = ['파일', '문서', '요약', '정보', '내용', '분석']\n",
    "        web_keywords = ['검색', '뉴스', '최신', '날씨', '현재', '찾아']\n",
    "        \n",
    "        response_content = \"\"\n",
    "        \n",
    "        # 파일이 업로드된 상태에서 파일 관련 질문\n",
    "        if st.session_state.file_processed and any(keyword in user_lower for keyword in file_keywords):\n",
    "            if '요약' in user_lower:\n",
    "                # 파일 요약\n",
    "                try:\n",
    "                    if st.session_state.chunks:\n",
    "                        content = \"\\n\".join(st.session_state.chunks[:5])\n",
    "                        if len(content) > 8000:\n",
    "                            content = content[:8000] + \"...\"\n",
    "                        \n",
    "                        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "                        prompt = f\"다음 내용을 한국어로 간단하고 명확하게 요약해주세요:\\n\\n{content}\\n\\n요약:\"\n",
    "                        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "                        response_content = response.content\n",
    "                    else:\n",
    "                        response_content = \"요약할 파일 내용이 없습니다.\"\n",
    "                except Exception as e:\n",
    "                    response_content = f\"요약 중 오류가 발생했습니다: {str(e)}\"\n",
    "                    \n",
    "            elif '정보' in user_lower:\n",
    "                # 파일 정보\n",
    "                response_content = get_document_info_tool_direct()\n",
    "                \n",
    "            else:\n",
    "                # 파일 검색\n",
    "                try:\n",
    "                    results = safe_search_documents(user_message, 3)\n",
    "                    if results:\n",
    "                        formatted_results = []\n",
    "                        for i, result in enumerate(results, 1):\n",
    "                            formatted_results.append(\n",
    "                                f\"[검색결과 {i}] (유사도: {result['score']:.3f})\\n\"\n",
    "                                f\"{result['content'][:400]}{'...' if len(result['content']) > 400 else ''}\\n\"\n",
    "                            )\n",
    "                        response_content = \"\\n\".join(formatted_results)\n",
    "                    else:\n",
    "                        response_content = f\"'{user_message}'에 대한 검색 결과가 없습니다.\"\n",
    "                except Exception as e:\n",
    "                    response_content = f\"검색 중 오류: {str(e)}\"\n",
    "        \n",
    "        # 웹 검색이 필요한 질문\n",
    "        elif any(keyword in user_lower for keyword in web_keywords):\n",
    "            try:\n",
    "                from langchain_community.tools import DuckDuckGoSearchRun\n",
    "                search_tool = DuckDuckGoSearchRun()\n",
    "                results = search_tool.run(user_message)\n",
    "                response_content = f\"🌐 웹 검색 결과:\\n\\n{results}\"\n",
    "            except ImportError:\n",
    "                response_content = f\"\"\"🔍 \"{user_message}\" 검색 링크:\n",
    "• Google: https://www.google.com/search?q={user_message.replace(' ', '+')}\n",
    "• 네이버: https://search.naver.com/search.naver?query={user_message.replace(' ', '+')}\n",
    "\n",
    "실시간 웹 검색: pip install duckduckgo-search\"\"\"\n",
    "            except Exception as e:\n",
    "                response_content = f\"웹 검색 중 오류: {str(e)}\"\n",
    "        \n",
    "        # 일반 질문\n",
    "        else:\n",
    "            try:\n",
    "                llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "                response = llm.invoke([HumanMessage(content=user_message)])\n",
    "                response_content = response.content\n",
    "            except Exception as e:\n",
    "                response_content = f\"일반 질문 처리 중 오류: {str(e)}\"\n",
    "        \n",
    "        # AI 응답 생성\n",
    "        ai_response = AIMessage(content=response_content)\n",
    "        return {\"messages\": messages + [ai_response]}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_response = AIMessage(content=f\"처리 중 오류가 발생했습니다: {str(e)}\")\n",
    "        return {\"messages\": messages + [error_response]}\n",
    "\n",
    "# 그래프 빌더 생성 (tool calling 제거)\n",
    "graph_builder = StateGraph(AgentState)\n",
    "graph_builder.add_node('agent', agent)\n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "graph_builder.add_edge('agent', END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# ============== 사용자 입력 처리 함수 ==============\n",
    "\n",
    "def process_user_input():\n",
    "    \"\"\"사용자 입력 처리 함수 - 중복 실행 방지\"\"\"\n",
    "    # 처리 중이면 무시\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    user_input = st.session_state.current_input.strip()\n",
    "    if not user_input:\n",
    "        return\n",
    "    \n",
    "    # 처리 상태 설정\n",
    "    st.session_state.processing = True\n",
    "    \n",
    "    try:\n",
    "        # 사용자 메시지 추가\n",
    "        st.session_state.chat_history.append((\"user\", user_input))\n",
    "        \n",
    "        # AI 응답 생성\n",
    "        if st.session_state.agent_graph is None:\n",
    "            st.session_state.agent_graph = graph\n",
    "        \n",
    "        # 새로운 대화 시작 (이전 메시지 체인 문제 방지)\n",
    "        initial_state = {\"messages\": [HumanMessage(content=user_input)]}\n",
    "        result = st.session_state.agent_graph.invoke(initial_state)\n",
    "        \n",
    "        # 응답 추출 (마지막 AI 메시지 찾기)\n",
    "        ai_response = None\n",
    "        if result and \"messages\" in result:\n",
    "            # 역순으로 검색하여 첫 번째 AI 메시지 찾기\n",
    "            for msg in reversed(result[\"messages\"]):\n",
    "                if isinstance(msg, AIMessage):\n",
    "                    ai_response = msg.content\n",
    "                    break\n",
    "        \n",
    "        if ai_response:\n",
    "            response = ai_response\n",
    "        else:\n",
    "            response = \"응답을 생성할 수 없습니다.\"\n",
    "        \n",
    "        # 채팅 히스토리에 추가\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"죄송합니다. 처리 중 오류가 발생했습니다: {str(e)}\"\n",
    "        st.session_state.chat_history.append((\"assistant\", error_msg))\n",
    "    \n",
    "    finally:\n",
    "        # 입력창 초기화 및 처리 상태 해제\n",
    "        st.session_state.current_input = \"\"\n",
    "        st.session_state.processing = False\n",
    "\n",
    "# ============== 빠른 버튼 처리 함수들 ==============\n",
    "\n",
    "def handle_quick_summary():\n",
    "    \"\"\"파일 요약 빠른 버튼 처리\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = summarize_content_tool_direct()\n",
    "        st.session_state.chat_history.append((\"user\", \"이 파일을 요약해줘\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"요약 중 오류: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_info():\n",
    "    \"\"\"파일 정보 빠른 버튼 처리\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = get_document_info_tool_direct()\n",
    "        st.session_state.chat_history.append((\"user\", \"파일 정보를 알려줘\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"정보 조회 중 오류: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_search():\n",
    "    \"\"\"키워드 검색 빠른 버튼 처리\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = search_uploaded_documents_direct(\"중요한 키워드\")\n",
    "        st.session_state.chat_history.append((\"user\", \"파일에서 중요한 키워드를 찾아줘\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"검색 중 오류: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_file_search():\n",
    "    \"\"\"파일 내 검색 빠른 버튼 처리\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = \"어떤 내용을 검색하고 싶으신가요? 구체적인 키워드나 질문을 입력해주세요.\"\n",
    "        st.session_state.chat_history.append((\"user\", \"파일에서 특정 내용을 검색하고 싶어\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"검색 중 오류: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_python():\n",
    "    \"\"\"파이썬 질문 빠른 버튼 처리\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = general_chat_tool_direct(\"파이썬에서 리스트와 튜플의 차이점은?\")\n",
    "        st.session_state.chat_history.append((\"user\", \"파이썬에서 리스트와 튜플의 차이점은?\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"답변 생성 중 오류: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_web_search():\n",
    "    \"\"\"웹 검색 빠른 버튼 처리\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = web_search_tool_direct(\"최신 AI 뉴스\")\n",
    "        st.session_state.chat_history.append((\"user\", \"최신 AI 뉴스를 검색해줘\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"검색 중 오류: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_ai_question():\n",
    "    \"\"\"AI 질문 빠른 버튼 처리\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = general_chat_tool_direct(\"ChatGPT와 Claude의 차이점은?\")\n",
    "        st.session_state.chat_history.append((\"user\", \"ChatGPT와 Claude의 차이점은?\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"답변 생성 중 오류: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "def handle_quick_coding():\n",
    "    \"\"\"코딩 질문 빠른 버튼 처리\"\"\"\n",
    "    if st.session_state.processing:\n",
    "        return\n",
    "    \n",
    "    st.session_state.processing = True\n",
    "    try:\n",
    "        response = general_chat_tool_direct(\"파이썬 클래스와 객체의 차이점을 설명해줘\")\n",
    "        st.session_state.chat_history.append((\"user\", \"파이썬 클래스와 객체의 차이점을 설명해줘\"))\n",
    "        st.session_state.chat_history.append((\"assistant\", response))\n",
    "    except Exception as e:\n",
    "        st.error(f\"답변 생성 중 오류: {e}\")\n",
    "    finally:\n",
    "        st.session_state.processing = False\n",
    "\n",
    "# ============== Streamlit UI ==============\n",
    "\n",
    "def main():\n",
    "    st.title(\"🤖 파일 분석 AI 어시스턴트\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # API 키 체크\n",
    "    if not os.getenv('OPENAI_API_KEY'):\n",
    "        st.error(\"⚠️ OpenAI API 키가 설정되지 않았습니다. .env 파일을 확인해주세요.\")\n",
    "        st.stop()\n",
    "    \n",
    "    # 사이드바\n",
    "    with st.sidebar:\n",
    "        st.header(\"📄 파일 업로드\")\n",
    "        \n",
    "        # 파일 업로드\n",
    "        uploaded_file = st.file_uploader(\n",
    "            \"파일을 선택하세요\",\n",
    "            type=['pdf', 'txt', 'md', 'py', 'js', 'html', 'css', 'json', 'xml', 'csv'],\n",
    "            help=\"PDF, 텍스트 파일, 코드 파일 등을 업로드할 수 있습니다.\"\n",
    "        )\n",
    "        \n",
    "        if uploaded_file is not None:\n",
    "            st.info(f\"📁 선택된 파일: {uploaded_file.name}\")\n",
    "            st.info(f\"📏 파일 크기: {uploaded_file.size:,} bytes\")\n",
    "            \n",
    "            if st.button(\"📊 파일 분석 시작\", type=\"primary\"):\n",
    "                with st.spinner(\"파일을 분석하는 중입니다...\"):\n",
    "                    try:\n",
    "                        # 텍스트 추출\n",
    "                        full_text = extract_text_from_file(uploaded_file)\n",
    "                        \n",
    "                        if full_text:\n",
    "                            # 청킹\n",
    "                            st.session_state.chunks = chunk_text(full_text)\n",
    "                            st.info(f\"✅ 청킹 완료! 총 {len(st.session_state.chunks)}개 청크 생성\")\n",
    "                            \n",
    "                            # 벡터 스토어 생성\n",
    "                            index, embedding_model, metadatas = create_vectorstore(st.session_state.chunks)\n",
    "                            \n",
    "                            if index is not None:\n",
    "                                st.session_state.index = index\n",
    "                                st.session_state.embedding_model = embedding_model\n",
    "                                st.session_state.metadatas = metadatas\n",
    "                                st.session_state.file_processed = True\n",
    "                                st.session_state.uploaded_filename = uploaded_file.name\n",
    "                                \n",
    "                                st.success(\"🎉 파일 분석이 완료되었습니다!\")\n",
    "                                st.balloons()\n",
    "                    except Exception as e:\n",
    "                        st.error(f\"파일 처리 중 오류: {e}\")\n",
    "        \n",
    "        # 문서 정보 표시\n",
    "        if st.session_state.file_processed:\n",
    "            st.markdown(\"---\")\n",
    "            st.header(\"📊 파일 정보\")\n",
    "            \n",
    "            if hasattr(st.session_state, 'uploaded_filename'):\n",
    "                st.info(f\"📁 파일명: {st.session_state.uploaded_filename}\")\n",
    "            \n",
    "            if st.session_state.chunks:\n",
    "                total_chars = sum(len(chunk) for chunk in st.session_state.chunks)\n",
    "                \n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    st.metric(\"청크 수\", len(st.session_state.chunks))\n",
    "                with col2:\n",
    "                    st.metric(\"총 글자 수\", f\"{total_chars:,}\")\n",
    "            \n",
    "            # 초기화 버튼\n",
    "            if st.button(\"🔄 초기화\", help=\"업로드된 파일을 초기화합니다\"):\n",
    "                for key in ['chunks', 'index', 'embedding_model', 'metadatas', 'file_processed', 'chat_history', 'uploaded_filename', 'file_metadata', 'pdf_metadata', 'current_input', 'processing']:\n",
    "                    if key in st.session_state:\n",
    "                        del st.session_state[key]\n",
    "                st.rerun()\n",
    "    \n",
    "    # 메인 콘텐츠 - 항상 채팅 인터페이스 표시\n",
    "    st.header(\"💬 AI 어시스턴트와 대화하기\")\n",
    "    \n",
    "    if not st.session_state.file_processed:\n",
    "        st.info(\"💡 일반 질문도 가능하고, 파일을 업로드하면 파일 분석도 할 수 있어요!\")\n",
    "        \n",
    "        # 사용법 안내\n",
    "        with st.expander(\"📖 사용법 안내\", expanded=False):\n",
    "            st.markdown(\"\"\"\n",
    "            ### 🚀 두 가지 사용 방법\n",
    "            \n",
    "            #### 1️⃣ 일반 AI 어시스턴트로 사용\n",
    "            - 바로 아래에서 질문하세요!\n",
    "            - 웹 검색, 일반 지식 질문 등 모든 질문 가능\n",
    "            \n",
    "            #### 2️⃣ 파일 분석 (다양한 형식 지원)\n",
    "            1. **파일 업로드**: 왼쪽 사이드바에서 파일을 업로드하세요\n",
    "               - 📄 **PDF**: 문서, 논문, 보고서 등\n",
    "               - 📝 **텍스트**: .txt, .md 파일\n",
    "               - 💻 **코드**: .py, .js, .html, .css, .json 등\n",
    "               - 📊 **데이터**: .csv, .xml 등\n",
    "            2. **분석 시작**: \"파일 분석 시작\" 버튼을 클릭하세요\n",
    "            3. **파일 질문**: 업로드한 파일에 대해 질문할 수 있습니다\n",
    "            \n",
    "            ### 💡 예시 질문\n",
    "            **일반 질문:**\n",
    "            - \"파이썬에서 리스트와 튜플의 차이점은?\"\n",
    "            - \"오늘 날씨는 어때?\"\n",
    "            - \"최신 AI 뉴스를 검색해줘\"\n",
    "            \n",
    "            **파일 질문 (업로드 후):**\n",
    "            - \"이 파일의 주요 내용을 요약해줘\"\n",
    "            - \"코드에서 함수들을 설명해줘\"\n",
    "            - \"파일에서 중요한 키워드를 찾아줘\"\n",
    "            - \"이 데이터의 패턴을 분석해줘\"\n",
    "            \"\"\")\n",
    "    \n",
    "    # 에이전트 그래프 초기화 (모든 tool 함수가 정의된 후에 실행)\n",
    "    try:\n",
    "        if st.session_state.agent_graph is None:\n",
    "            st.session_state.agent_graph = graph\n",
    "    except Exception as e:\n",
    "        st.error(f\"AI 초기화 중 오류: {e}\")\n",
    "        st.info(\"페이지를 새로고침해주세요.\")\n",
    "    \n",
    "    # 채팅 히스토리 표시\n",
    "    chat_container = st.container()\n",
    "    \n",
    "    with chat_container:\n",
    "        for i, (role, message) in enumerate(st.session_state.chat_history):\n",
    "            if role == \"user\":\n",
    "                with st.chat_message(\"user\"):\n",
    "                    st.write(message)\n",
    "            else:\n",
    "                with st.chat_message(\"assistant\"):\n",
    "                    st.write(message)\n",
    "    \n",
    "    # 사용자 입력 (항상 맨 아래에 고정)\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"✍️ 질문하기\")\n",
    "    \n",
    "    # 텍스트 입력과 버튼을 같은 행에 배치\n",
    "    col1, col2 = st.columns([4, 1])\n",
    "    \n",
    "    with col1:\n",
    "        # on_change 콜백을 사용하여 엔터키 처리\n",
    "        user_input = st.text_input(\n",
    "            \"질문을 입력하세요\",\n",
    "            value=st.session_state.current_input,\n",
    "            placeholder=\"예: '파이썬이란?' 또는 '파일을 요약해줘' (Enter 또는 전송 버튼)\",\n",
    "            key=\"text_input\",\n",
    "            on_change=process_user_input\n",
    "        )\n",
    "        # 입력값을 세션 상태에 동기화\n",
    "        st.session_state.current_input = user_input\n",
    "    \n",
    "    with col2:\n",
    "        # 전송 버튼 클릭 처리\n",
    "        if st.button(\"전송\", type=\"primary\", use_container_width=True):\n",
    "            process_user_input()\n",
    "            st.rerun()\n",
    "    \n",
    "    # 빠른 질문 버튼들\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    if st.session_state.file_processed:\n",
    "        st.subheader(\"🎯 파일 관련 빠른 질문\")\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "        \n",
    "        with col1:\n",
    "            if st.button(\"📝 파일 요약\", on_click=handle_quick_summary):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col2:\n",
    "            if st.button(\"📊 파일 정보\", on_click=handle_quick_info):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col3:\n",
    "            if st.button(\"🔍 키워드 검색\", on_click=handle_quick_search):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col4:\n",
    "            if st.button(\"📄 파일 내 검색\", on_click=handle_quick_file_search):\n",
    "                st.rerun()\n",
    "    \n",
    "    else:\n",
    "        st.subheader(\"🎯 일반 질문 예시\")\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "        \n",
    "        with col1:\n",
    "            if st.button(\"🐍 파이썬 질문\", on_click=handle_quick_python):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col2:\n",
    "            if st.button(\"🌐 웹 검색\", on_click=handle_quick_web_search):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col3:\n",
    "            if st.button(\"🤖 AI 질문\", on_click=handle_quick_ai_question):\n",
    "                st.rerun()\n",
    "        \n",
    "        with col4:\n",
    "            if st.button(\"💻 코딩 질문\", on_click=handle_quick_coding):\n",
    "                st.rerun()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "• \"이 문서의 핵심 내용을 요약해줘\"\n",
    "• \"특정 키워드를 검색해줘\"\n",
    "• \"문서에서 중요한 부분을 찾아줘\"\n",
    "\"\"\"\n",
    "\n",
    "        return info_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"파일 정보 조회 중 오류: {str(e)}\"\n",
    "\n",
    "# ============== 직접 호출 함수들 (빠른 버튼용) ==============\n",
    "\n",
    "def search_uploaded_documents_direct(query: str, k: int = 3) -> str:\n",
    "    \"\"\"업로드된 파일에서 내용을 검색합니다. (직접 호출용)\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"업로드된 파일이 없습니다. 먼저 파일을 업로드하고 처리해주세요.\"\n",
    "        \n",
    "        results = safe_search_documents(query, k)\n",
    "        \n",
    "        if not results:\n",
    "            return f\"'{query}'에 대한 검색 결과가 없습니다.\"\n",
    "        \n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            formatted_results.append(\n",
    "                f\"[검색결과 {i}] (유사도: {result['score']:.3f})\\n\"\n",
    "                f\"{result['content'][:400]}{'...' if len(result['content']) > 400 else ''}\\n\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n\".join(formatted_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"파일 검색 중 오류: {str(e)}\"\n",
    "\n",
    "def web_search_tool_direct(query: str) -> str:\n",
    "    \"\"\"웹에서 최신 정보를 검색합니다. (직접 호출용)\"\"\"\n",
    "    try:\n",
    "        from langchain_community.tools import DuckDuckGoSearchRun\n",
    "        search_tool = DuckDuckGoSearchRun()\n",
    "        results = search_tool.run(query)\n",
    "        return f\"🌐 웹 검색 결과:\\n\\n{results}\"\n",
    "    except ImportError:\n",
    "        return f\"\"\"🔍 \"{query}\" 검색 링크:\n",
    "• Google: https://www.google.com/search?q={query.replace(' ', '+')}\n",
    "• 네이버: https://search.naver.com/search.naver?query={query.replace(' ', '+')}\n",
    "\n",
    "실시간 웹 검색: pip install duckduckgo-search\"\"\"\n",
    "    except Exception as e:\n",
    "        return f\"웹 검색 중 오류: {str(e)}\"\n",
    "\n",
    "def general_chat_tool_direct(question: str) -> str:\n",
    "    \"\"\"일반적인 질문에 답변합니다. (직접 호출용)\"\"\"\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "        response = llm.invoke([HumanMessage(content=question)])\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"일반 질문 처리 중 오류: {str(e)}\"\n",
    "\n",
    "def summarize_content_tool_direct(content: str = \"\", style: str = \"general\") -> str:\n",
    "    \"\"\"주어진 내용을 요약합니다. (직접 호출용)\"\"\"\n",
    "    try:\n",
    "        # content가 비어있으면 업로드된 파일 사용\n",
    "        if not content.strip():\n",
    "            if (not hasattr(st.session_state, 'file_processed') or \n",
    "                not st.session_state.file_processed or\n",
    "                not hasattr(st.session_state, 'chunks') or\n",
    "                not st.session_state.chunks):\n",
    "                return \"요약할 파일이 없습니다. 먼저 파일을 업로드하고 처리해주세요.\"\n",
    "            \n",
    "            # 처음 5개 청크를 요약 (더 많은 내용)\n",
    "            content = \"\\n\".join(st.session_state.chunks[:5])\n",
    "        \n",
    "        if not content.strip():\n",
    "            return \"요약할 내용이 없습니다.\"\n",
    "        \n",
    "        # 내용이 너무 길면 잘라서 처리\n",
    "        if len(content) > 8000:\n",
    "            content = content[:8000] + \"...\"\n",
    "        \n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "        \n",
    "        # 간단한 요약 프롬프트\n",
    "        prompt = f\"\"\"다음 내용을 한국어로 간단하고 명확하게 요약해주세요:\n",
    "\n",
    "{content}\n",
    "\n",
    "요약:\"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        return response.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"요약 중 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "def get_document_info_tool_direct() -> str:\n",
    "    \"\"\"현재 로드된 파일의 정보를 반환합니다. (직접 호출용)\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"로드된 파일이 없습니다. 파일을 먼저 업로드하고 처리해주세요.\"\n",
    "        \n",
    "        if not hasattr(st.session_state, 'chunks') or not st.session_state.chunks:\n",
    "            return \"파일 처리 정보가 없습니다.\"\n",
    "        \n",
    "        # 기본 통계 정보\n",
    "        total_chars = sum(len(chunk) for chunk in st.session_state.chunks)\n",
    "        filename = getattr(st.session_state, 'uploaded_filename', '알 수 없음')\n",
    "        \n",
    "        # 파일 메타데이터 가져오기\n",
    "        file_meta = getattr(st.session_state, 'file_metadata', {})\n",
    "        pdf_meta = getattr(st.session_state, 'pdf_metadata', {})\n",
    "        \n",
    "        info_text = f\"\"\"📄 **파일 정보**\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "📁 **기본 정보**\n",
    "• 파일명: {filename}\n",
    "• 파일 형식: {file_meta.get('file_type', '알 수 없음')}\n",
    "• 파일 크기: {file_meta.get('file_size_mb', 0)} MB ({file_meta.get('file_size', 0):,} bytes)\n",
    "\"\"\"\n",
    "\n",
    "        # PDF 메타데이터가 있는 경우\n",
    "        if pdf_meta:\n",
    "            info_text += f\"\"\"\n",
    "📖 **PDF 문서 정보**\n",
    "• 제목: {pdf_meta.get('title', '제목 없음')}\n",
    "• 작성자: {pdf_meta.get('author', '작성자 없음')}\n",
    "• 주제: {pdf_meta.get('subject', '주제 없음')}\n",
    "• 총 페이지 수: {pdf_meta.get('total_pages', '알 수 없음')}페이지\n",
    "• 생성 프로그램: {pdf_meta.get('creator', '알 수 없음')}\n",
    "• 제작 프로그램: {pdf_meta.get('producer', '알 수 없음')}\n",
    "• 생성일: {pdf_meta.get('creationDate', '알 수 없음')}\n",
    "• 수정일: {pdf_meta.get('modDate', '알 수 없음')}\n",
    "\"\"\"\n",
    "\n",
    "        # 텍스트 파일 메타데이터가 있는 경우\n",
    "        if 'lines' in file_meta:\n",
    "            info_text += f\"\"\"\n",
    "📝 **{file_meta.get('file_type_name', '텍스트 파일')} 정보**\n",
    "• 파일 형식: {file_meta.get('extension', 'TXT')} 파일\n",
    "• 인코딩: {file_meta.get('encoding', '알 수 없음')}\n",
    "• 총 줄 수: {file_meta.get('lines', 0):,}줄\n",
    "• 총 단어 수: {file_meta.get('words', 0):,}개\n",
    "• 총 문자 수: {file_meta.get('characters', 0):,}자\n",
    "• 내용이 있는 줄: {file_meta.get('paragraphs', 0):,}줄\n",
    "• 빈 줄: {file_meta.get('empty_lines', 0):,}줄\n",
    "\"\"\"\n",
    "\n",
    "        info_text += f\"\"\"\n",
    "🔧 **분석 정보**\n",
    "• 청크 수: {len(st.session_state.chunks):,}개\n",
    "• 총 텍스트 길이: {total_chars:,}자\n",
    "• 평균 청크 크기: {total_chars // len(st.session_state.chunks):,}자\n",
    "\n",
    "🛠️ **사용 가능한 기능**\n",
    "• 📝 파일 내용 요약\n",
    "• 🔍 키워드/내용 검색  \n",
    "• 🌐 웹 검색과 비교\n",
    "• 💬 파일 관련 질의응답\n",
    "\n",
    "💡 **예시 질문**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e26deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== 직접 호출 함수들 (tool 데코레이터 제거) ==============\n",
    "\n",
    "@tool\n",
    "def search_uploaded_documents_direct(query: str, k: int = 3) -> str:\n",
    "    \"\"\"업로드된 파일에서 내용을 검색합니다.\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"업로드된 파일이 없습니다. 먼저 파일을 업로드하고 처리해주세요.\"\n",
    "        \n",
    "        results = safe_search_documents(query, k)\n",
    "        \n",
    "        if not results:\n",
    "            return f\"'{query}'에 대한 검색 결과가 없습니다.\"\n",
    "        \n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            formatted_results.append(\n",
    "                f\"[검색결과 {i}] (유사도: {result['score']:.3f})\\n\"\n",
    "                f\"{result['content'][:400]}{'...' if len(result['content']) > 400 else ''}\\n\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n\".join(formatted_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"파일 검색 중 오류: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def web_search_tool_direct(query: str) -> str:\n",
    "    \"\"\"웹에서 최신 정보를 검색합니다.\"\"\"\n",
    "    try:\n",
    "        from langchain_community.tools import DuckDuckGoSearchRun\n",
    "        search_tool = DuckDuckGoSearchRun()\n",
    "        results = search_tool.run(query)\n",
    "        return f\"🌐 웹 검색 결과:\\n\\n{results}\"\n",
    "    except ImportError:\n",
    "        return f\"\"\"🔍 \"{query}\" 검색 링크:\n",
    "• Google: https://www.google.com/search?q={query.replace(' ', '+')}\n",
    "• 네이버: https://search.naver.com/search.naver?query={query.replace(' ', '+')}\n",
    "\n",
    "실시간 웹 검색: pip install duckduckgo-search\"\"\"\n",
    "    except Exception as e:\n",
    "        return f\"웹 검색 중 오류: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def general_chat_tool_direct(question: str) -> str:\n",
    "    \"\"\"일반적인 질문에 답변합니다.\"\"\"\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "        response = llm.invoke([HumanMessage(content=question)])\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"일반 질문 처리 중 오류: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def summarize_content_tool_direct(content: str = \"\", style: str = \"general\") -> str:\n",
    "    \"\"\"주어진 내용을 요약합니다.\"\"\"\n",
    "    try:\n",
    "        # content가 비어있으면 업로드된 파일 사용\n",
    "        if not content.strip():\n",
    "            if (not hasattr(st.session_state, 'file_processed') or \n",
    "                not st.session_state.file_processed or\n",
    "                not hasattr(st.session_state, 'chunks') or\n",
    "                not st.session_state.chunks):\n",
    "                return \"요약할 파일이 없습니다. 먼저 파일을 업로드하고 처리해주세요.\"\n",
    "            \n",
    "            # 처음 5개 청크를 요약 (더 많은 내용)\n",
    "            content = \"\\n\".join(st.session_state.chunks[:5])\n",
    "        \n",
    "        if not content.strip():\n",
    "            return \"요약할 내용이 없습니다.\"\n",
    "        \n",
    "        # 내용이 너무 길면 잘라서 처리\n",
    "        if len(content) > 8000:\n",
    "            content = content[:8000] + \"...\"\n",
    "        \n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "        \n",
    "        # 간단한 요약 프롬프트\n",
    "        prompt = f\"\"\"다음 내용을 한국어로 간단하고 명확하게 요약해주세요:\n",
    "\n",
    "{content}\n",
    "\n",
    "요약:\"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        return response.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"요약 중 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_document_info_tool_direct() -> str:\n",
    "    \"\"\"현재 로드된 파일의 정보를 반환합니다.\"\"\"\n",
    "    try:\n",
    "        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:\n",
    "            return \"로드된 파일이 없습니다. 파일을 먼저 업로드하고 처리해주세요.\"\n",
    "        \n",
    "        if not hasattr(st.session_state, 'chunks') or not st.session_state.chunks:\n",
    "            return \"파일 처리 정보가 없습니다.\"\n",
    "        \n",
    "        total_chars = sum(len(chunk) for chunk in st.session_state.chunks)\n",
    "        filename = getattr(st.session_state, 'uploaded_filename', '알 수 없음')\n",
    "        \n",
    "        return f\"\"\"📄 현재 로드된 파일 정보:\n",
    "- 파일명: {filename}\n",
    "- 총 청크 수: {len(st.session_state.chunks)}\n",
    "- 총 글자 수: {total_chars:,}\n",
    "- 평균 청크 크기: {total_chars // len(st.session_state.chunks):,} 글자\n",
    "\n",
    "🛠️ 사용 가능한 기능들:\n",
    "- 파일 내용 검색\n",
    "- 웹에서 최신 정보 검색\n",
    "- 내용 요약\n",
    "- 파일 정보 조회\n",
    "\n",
    "💡 예시 질문: \"파일에서 중요한 부분을 찾아줘\", \"파일을 요약해줘\" \"\"\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"파일 정보 조회 중 오류: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d8747be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_list = [search_uploaded_documents_direct, web_search_tool_direct, general_chat_tool_direct, summarize_content_tool_direct, get_document_info_tool_direct ]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tool_list)\n",
    "tool_node = ToolNode(tool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddd20ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"다음 단계를 결정하는 함수\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return END\n",
    "\n",
    "def agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"LLM 모델 호출\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # 마지막 메시지가 사용자 메시지인지 확인\n",
    "    if not messages or not isinstance(messages[-1], HumanMessage):\n",
    "        return state\n",
    "    \n",
    "    user_message = messages[-1].content\n",
    "    \n",
    "    try:\n",
    "        # 간단한 키워드 기반 라우팅\n",
    "        user_lower = user_message.lower()\n",
    "        \n",
    "        # 파일 관련 질문 감지\n",
    "        file_keywords = ['파일', '문서', '요약', '검색', '정보', '내용']\n",
    "        is_file_related = any(keyword in user_lower for keyword in file_keywords)\n",
    "        \n",
    "        # 웹 검색 키워드 감지\n",
    "        web_keywords = ['검색', '뉴스', '최신', '날씨', '현재']\n",
    "        needs_web_search = any(keyword in user_lower for keyword in web_keywords)\n",
    "        \n",
    "        response_content = \"\"\n",
    "        \n",
    "        if is_file_related and st.session_state.file_processed:\n",
    "            # 파일 관련 처리\n",
    "            if '요약' in user_lower:\n",
    "                response_content = summarize_content_tool_direct()\n",
    "            elif '정보' in user_lower:\n",
    "                response_content = get_document_info_tool_direct()\n",
    "            else:\n",
    "                response_content = search_uploaded_documents_direct(user_message)\n",
    "        \n",
    "        elif needs_web_search:\n",
    "            # 웹 검색 처리\n",
    "            response_content = web_search_tool_direct(user_message)\n",
    "        \n",
    "        else:\n",
    "            # 일반 채팅 처리\n",
    "            response_content = general_chat_tool_direct(user_message)\n",
    "        \n",
    "        # AI 응답 생성\n",
    "        ai_response = AIMessage(content=response_content)\n",
    "        return {\"messages\": messages + [ai_response]}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_response = AIMessage(content=f\"죄송합니다. 처리 중 오류가 발생했습니다: {str(e)}\")\n",
    "        return {\"messages\": messages + [error_response]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ecd960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 14:14:22.849 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000118F99CDE10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  langgraph.graph import START, END\n",
    "graph_builder = StateGraph(AgentState)\n",
    "graph_builder.add_node('agent', agent)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "graph_builder.add_conditional_edges(\n",
    "    'agent',\n",
    "    should_continue,\n",
    "    ['tools', END]\n",
    ")\n",
    "graph_builder.add_edge('tools', 'agent')\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da1ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
