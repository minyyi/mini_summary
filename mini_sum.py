# ============== PDF ë¶„ì„ Streamlit ì•± ==============
import streamlit as st
import fitz  # pymupdf
import faiss
import numpy as np
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END, START
from langgraph.prebuilt import ToolNode
from typing import TypedDict, List, Dict, Any
import pickle
import os
import tempfile
from dotenv import load_dotenv
import time

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="íŒŒì¼ ë¶„ì„ AI ì–´ì‹œìŠ¤í„´íŠ¸",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# í™˜ê²½ ì„¤ì •
load_dotenv()

# ============== ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ==============
def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”"""
    if 'chunks' not in st.session_state:
        st.session_state.chunks = []
    if 'index' not in st.session_state:
        st.session_state.index = None
    if 'embedding_model' not in st.session_state:
        st.session_state.embedding_model = None
    if 'metadatas' not in st.session_state:
        st.session_state.metadatas = []
    if 'file_processed' not in st.session_state:
        st.session_state.file_processed = False
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'agent_graph' not in st.session_state:
        st.session_state.agent_graph = None
    if 'uploaded_filename' not in st.session_state:
        st.session_state.uploaded_filename = ""
    if 'file_metadata' not in st.session_state:
        st.session_state.file_metadata = {}
    if 'pdf_metadata' not in st.session_state:
        st.session_state.pdf_metadata = {}
    if 'current_input' not in st.session_state:
        st.session_state.current_input = ""
    if 'processing' not in st.session_state:
        st.session_state.processing = False

# ì´ˆê¸°í™” ì‹¤í–‰
init_session_state()

# ============== íƒ€ì… ì •ì˜ ==============
class AgentState(TypedDict):
    messages: List[Any]

# ============== íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ==============

def extract_text_from_file(uploaded_file):
    """ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    file_type = uploaded_file.type
    file_name = uploaded_file.name.lower()
    
    # ê¸°ë³¸ íŒŒì¼ ì •ë³´ ì €ì¥
    st.session_state.file_metadata = {
        'filename': uploaded_file.name,
        'file_type': file_type,
        'file_size': uploaded_file.size,
        'file_size_mb': round(uploaded_file.size / (1024*1024), 2)
    }
    
    try:
        if file_type == "application/pdf" or file_name.endswith('.pdf'):
            return extract_text_with_fitz(uploaded_file)
        
        elif file_type == "text/plain" or file_name.endswith(('.txt', '.md', '.py', '.js', '.html', '.css', '.json', '.xml', '.csv')):
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
            content = uploaded_file.read()
            if isinstance(content, bytes):
                # ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
                for encoding in ['utf-8', 'cp949', 'euc-kr', 'latin-1']:
                    try:
                        text = content.decode(encoding)
                        st.success(f"âœ… í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì™„ë£Œ! ({encoding} ì¸ì½”ë”©)")
                        
                        # í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                        lines = text.split('\n')
                        words = text.split()
                        
                        # íŒŒì¼ í™•ì¥ìë¡œ íŒŒì¼ ìœ í˜• íŒë‹¨
                        file_ext = file_name.split('.')[-1] if '.' in file_name else 'txt'
                        file_type_name = {
                            'py': 'Python ì½”ë“œ',
                            'js': 'JavaScript ì½”ë“œ', 
                            'html': 'HTML ë¬¸ì„œ',
                            'css': 'CSS ìŠ¤íƒ€ì¼ì‹œíŠ¸',
                            'json': 'JSON ë°ì´í„°',
                            'xml': 'XML ë¬¸ì„œ',
                            'csv': 'CSV ë°ì´í„°',
                            'md': 'Markdown ë¬¸ì„œ',
                            'txt': 'í…ìŠ¤íŠ¸ ë¬¸ì„œ'
                        }.get(file_ext, 'í…ìŠ¤íŠ¸ íŒŒì¼')
                        
                        st.session_state.file_metadata.update({
                            'encoding': encoding,
                            'lines': len(lines),
                            'words': len(words),
                            'characters': len(text),
                            'file_type_name': file_type_name,
                            'extension': file_ext.upper(),
                            'paragraphs': len([line for line in lines if line.strip()]),
                            'empty_lines': len([line for line in lines if not line.strip()])
                        })
                        
                        return text
                    except UnicodeDecodeError:
                        continue
                st.error("âŒ í…ìŠ¤íŠ¸ íŒŒì¼ ì¸ì½”ë”©ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return ""
            else:
                return str(content)
        
        else:
            st.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_type}")
            return ""
            
    except Exception as e:
        st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return ""

def extract_text_with_fitz(pdf_file):
    """PyMuPDFë¡œ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            tmp_file.write(pdf_file.read())
            tmp_path = tmp_file.name
        
        doc = fitz.open(tmp_path)
        
        # PDF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = doc.metadata
        st.session_state.pdf_metadata = {
            'title': metadata.get('title', 'ì œëª© ì—†ìŒ'),
            'author': metadata.get('author', 'ì‘ì„±ì ì—†ìŒ'),
            'subject': metadata.get('subject', 'ì£¼ì œ ì—†ìŒ'),
            'creator': metadata.get('creator', 'ìƒì„± í”„ë¡œê·¸ë¨ ì—†ìŒ'),
            'producer': metadata.get('producer', 'ì œì‘ í”„ë¡œê·¸ë¨ ì—†ìŒ'),
            'creationDate': metadata.get('creationDate', 'ìƒì„±ì¼ ì—†ìŒ'),
            'modDate': metadata.get('modDate', 'ìˆ˜ì •ì¼ ì—†ìŒ'),
            'total_pages': len(doc)
        }
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        full_text = ""
        total_pages = len(doc)
        
        for page_num in range(total_pages):
            progress = (page_num + 1) / total_pages
            progress_bar.progress(progress)
            status_text.text(f"í˜ì´ì§€ {page_num + 1}/{total_pages} ì²˜ë¦¬ ì¤‘...")
            
            page = doc[page_num]
            text = page.get_text()
            
            if text and text.strip():
                text = text.replace('\x00', '')
                text = text.replace('\ufeff', '')
                text = text.replace('\r\n', '\n')
                text = text.replace('\r', '\n')
                full_text += text + "\n\n"
        
        doc.close()
        os.unlink(tmp_path)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        
        progress_bar.progress(1.0)
        status_text.text(f"âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ! ì´ {len(full_text)} ê¸€ì")
        time.sleep(1)
        progress_bar.empty()
        status_text.empty()
        
        return full_text
        
    except Exception as e:
        st.error(f"âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return ""

def chunk_text(text, chunk_size=2000, overlap=100):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜"""
    if not text.strip():
        return []
    
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end].strip()
        
        if chunk:
            chunks.append(chunk)
        
        start = end - overlap
    
    return chunks

def create_vectorstore(chunks):
    """FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
    if not chunks:
        return None, None, None
    
    try:
        with st.spinner('ğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)'):
            embedding_model = OpenAIEmbeddings(model='text-embedding-3-large')
            embeddings = embedding_model.embed_documents(chunks)
            embeddings = np.array(embeddings).astype('float32')
            
            # FAISS ì¸ë±ìŠ¤ ìƒì„±
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatL2(dimension)
            index.add(embeddings)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            metadatas = []
            for i, chunk in enumerate(chunks):
                metadatas.append({
                    'chunk_id': i,
                    'chunk_size': len(chunk),
                    'preview': chunk[:100] + "..." if len(chunk) > 100 else chunk
                })
        
        st.success(f"âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ! {index.ntotal}ê°œ ë²¡í„° ì €ì¥")
        return index, embedding_model, metadatas
        
    except Exception as e:
        st.error(f"âŒ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì˜¤ë¥˜: {e}")
        return None, None, None

def safe_search_documents(query, k=3):
    """ì•ˆì „í•œ ë¬¸ì„œ ê²€ìƒ‰"""
    try:
        if (not hasattr(st.session_state, 'index') or 
            st.session_state.index is None or 
            not hasattr(st.session_state, 'embedding_model') or
            st.session_state.embedding_model is None):
            return []
        
        query_embedding = st.session_state.embedding_model.embed_query(query)
        query_embedding = np.array([query_embedding]).astype('float32')
        
        distances, indices = st.session_state.index.search(query_embedding, k)
        
        results = []
        for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):
            if idx < len(st.session_state.chunks):
                results.append({
                    'chunk_id': idx,
                    'content': st.session_state.chunks[idx],
                    'score': 1.0 - (distance / 2.0),
                    'metadata': st.session_state.metadatas[idx] if idx < len(st.session_state.metadatas) else {}
                })
        
        return results
        
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

# ============== LangGraph Tools ==============

@tool
def search_uploaded_documents(query: str) -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:
            return "ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”."
        
        results = safe_search_documents(query, 3)
        
        if not results:
            return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        formatted_results = []
        for i, result in enumerate(results, 1):
            formatted_results.append(
                # f"[ê²€ìƒ‰ê²°ê³¼ {i}] (ìœ ì‚¬ë„: {result['score']:.3f})\n"
                f"{result['content'][:400]}{'...' if len(result['content']) > 400 else ''}\n"
            )
        
        return "\n".join(formatted_results)
        
    except Exception as e:
        return f"íŒŒì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"

@tool
def web_search_tool(query: str) -> str:
    """ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        from langchain_community.tools import DuckDuckGoSearchRun
        search_tool = DuckDuckGoSearchRun()
        results = search_tool.run(query)
        return f"ğŸŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼:\n\n{results}"
    except ImportError:
        return f"""ğŸ” "{query}" ê²€ìƒ‰ ë§í¬:
â€¢ Google: https://www.google.com/search?q={query.replace(' ', '+')}
â€¢ ë„¤ì´ë²„: https://search.naver.com/search.naver?query={query.replace(' ', '+')}

ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰: pip install duckduckgo-search"""
    except Exception as e:
        return f"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"

@tool
def general_chat_tool(question: str) -> str:
    """ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤."""
    try:
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
        response = llm.invoke([HumanMessage(content=question)])
        return response.content
    except Exception as e:
        return f"ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"

@tool
def summarize_content_tool() -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì˜ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤."""
    try:
        if (not hasattr(st.session_state, 'file_processed') or 
            not st.session_state.file_processed or
            not hasattr(st.session_state, 'chunks') or
            not st.session_state.chunks):
            return "ìš”ì•½í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”."
        
        # ì²˜ìŒ 5ê°œ ì²­í¬ë¥¼ ìš”ì•½ (ë” ë§ì€ ë‚´ìš©)
        content = "\n".join(st.session_state.chunks[:5])
        
        if not content.strip():
            return "ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì²˜ë¦¬
        if len(content) > 8000:
            content = content[:8000] + "..."
        
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
        
        # ê°„ë‹¨í•œ ìš”ì•½ í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{content}

ìš”ì•½:"""
        
        response = llm.invoke([HumanMessage(content=prompt)])
        return response.content
        
    except Exception as e:
        return f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

@tool
def get_document_info_tool() -> str:
    """í˜„ì¬ ë¡œë“œëœ íŒŒì¼ì˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        if not hasattr(st.session_state, 'file_processed') or not st.session_state.file_processed:
            return "ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”."
        
        if not hasattr(st.session_state, 'chunks') or not st.session_state.chunks:
            return "íŒŒì¼ ì²˜ë¦¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ê¸°ë³¸ í†µê³„ ì •ë³´
        total_chars = sum(len(chunk) for chunk in st.session_state.chunks)
        filename = getattr(st.session_state, 'uploaded_filename', 'ì•Œ ìˆ˜ ì—†ìŒ')
        
        # íŒŒì¼ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        file_meta = getattr(st.session_state, 'file_metadata', {})
        pdf_meta = getattr(st.session_state, 'pdf_metadata', {})
        
        info_text = f"""ğŸ“„ **íŒŒì¼ ì •ë³´**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ **ê¸°ë³¸ ì •ë³´**
â€¢ íŒŒì¼ëª…: {filename}
â€¢ íŒŒì¼ í˜•ì‹: {file_meta.get('file_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}
â€¢ íŒŒì¼ í¬ê¸°: {file_meta.get('file_size_mb', 0)} MB ({file_meta.get('file_size', 0):,} bytes)
"""

        # PDF ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
        if pdf_meta:
            info_text += f"""
ğŸ“– **PDF ë¬¸ì„œ ì •ë³´**
â€¢ ì œëª©: {pdf_meta.get('title', 'ì œëª© ì—†ìŒ')}
â€¢ ì‘ì„±ì: {pdf_meta.get('author', 'ì‘ì„±ì ì—†ìŒ')}
â€¢ ì£¼ì œ: {pdf_meta.get('subject', 'ì£¼ì œ ì—†ìŒ')}
â€¢ ì´ í˜ì´ì§€ ìˆ˜: {pdf_meta.get('total_pages', 'ì•Œ ìˆ˜ ì—†ìŒ')}í˜ì´ì§€
â€¢ ìƒì„± í”„ë¡œê·¸ë¨: {pdf_meta.get('creator', 'ì•Œ ìˆ˜ ì—†ìŒ')}
â€¢ ì œì‘ í”„ë¡œê·¸ë¨: {pdf_meta.get('producer', 'ì•Œ ìˆ˜ ì—†ìŒ')}
â€¢ ìƒì„±ì¼: {pdf_meta.get('creationDate', 'ì•Œ ìˆ˜ ì—†ìŒ')}
â€¢ ìˆ˜ì •ì¼: {pdf_meta.get('modDate', 'ì•Œ ìˆ˜ ì—†ìŒ')}
"""

        # í…ìŠ¤íŠ¸ íŒŒì¼ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
        if 'lines' in file_meta:
            info_text += f"""
ğŸ“ **{file_meta.get('file_type_name', 'í…ìŠ¤íŠ¸ íŒŒì¼')} ì •ë³´**
â€¢ íŒŒì¼ í˜•ì‹: {file_meta.get('extension', 'TXT')} íŒŒì¼
â€¢ ì¸ì½”ë”©: {file_meta.get('encoding', 'ì•Œ ìˆ˜ ì—†ìŒ')}
â€¢ ì´ ì¤„ ìˆ˜: {file_meta.get('lines', 0):,}ì¤„
â€¢ ì´ ë‹¨ì–´ ìˆ˜: {file_meta.get('words', 0):,}ê°œ
â€¢ ì´ ë¬¸ì ìˆ˜: {file_meta.get('characters', 0):,}ì
â€¢ ë‚´ìš©ì´ ìˆëŠ” ì¤„: {file_meta.get('paragraphs', 0):,}ì¤„
â€¢ ë¹ˆ ì¤„: {file_meta.get('empty_lines', 0):,}ì¤„
"""

        info_text += f"""
ğŸ”§ **ë¶„ì„ ì •ë³´**
â€¢ ì²­í¬ ìˆ˜: {len(st.session_state.chunks):,}ê°œ
â€¢ ì´ í…ìŠ¤íŠ¸ ê¸¸ì´: {total_chars:,}ì
â€¢ í‰ê·  ì²­í¬ í¬ê¸°: {total_chars // len(st.session_state.chunks):,}ì

ğŸ› ï¸ **ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥**
â€¢ ğŸ“ íŒŒì¼ ë‚´ìš© ìš”ì•½
â€¢ ğŸ” í‚¤ì›Œë“œ/ë‚´ìš© ê²€ìƒ‰  
â€¢ ğŸŒ ì›¹ ê²€ìƒ‰ê³¼ ë¹„êµ
â€¢ ğŸ’¬ íŒŒì¼ ê´€ë ¨ ì§ˆì˜ì‘ë‹µ

ğŸ’¡ **ì˜ˆì‹œ ì§ˆë¬¸**
â€¢ "ì´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜"
â€¢ "íŠ¹ì • í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•´ì¤˜"
â€¢ "ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ì°¾ì•„ì¤˜"
"""

        return info_text
    
    except Exception as e:
        return f"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}"

# ============== LangGraph ê·¸ë˜í”„ ==============

def should_continue(state: AgentState) -> str:
    """ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ - tool calling ì œê±°ë¡œ í•­ìƒ END"""
    return END

def agent(state: AgentState) -> AgentState:
    """LLM ì—ì´ì „íŠ¸ í•¨ìˆ˜ - í‚¤ì›Œë“œ ê¸°ë°˜ ë¼ìš°íŒ…ìœ¼ë¡œ tool calling ì—ëŸ¬ ë°©ì§€"""
    messages = state["messages"]
    
    # ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ
    if not messages:
        return {"messages": [AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")]}
    
    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    user_message = ""
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            user_message = msg.content
            break
    
    if not user_message:
        return {"messages": messages + [AIMessage(content="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")]}
    
    try:
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¼ìš°íŒ…ìœ¼ë¡œ tool calling ëŒ€ì‹  ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ
        user_lower = user_message.lower()
        
        # íŒŒì¼ ê´€ë ¨ í‚¤ì›Œë“œ
        file_keywords = ['íŒŒì¼', 'ë¬¸ì„œ', 'ìš”ì•½', 'ì •ë³´', 'ë‚´ìš©', 'ë¶„ì„']
        web_keywords = ['ê²€ìƒ‰', 'ë‰´ìŠ¤', 'ìµœì‹ ', 'ë‚ ì”¨', 'í˜„ì¬', 'ì°¾ì•„']
        
        response_content = ""
        
        # íŒŒì¼ì´ ì—…ë¡œë“œëœ ìƒíƒœì—ì„œ íŒŒì¼ ê´€ë ¨ ì§ˆë¬¸
        if st.session_state.file_processed and any(keyword in user_lower for keyword in file_keywords):
            if 'ìš”ì•½' in user_lower:
                # íŒŒì¼ ìš”ì•½
                try:
                    if st.session_state.chunks:
                        content = "\n".join(st.session_state.chunks[:5])
                        if len(content) > 8000:
                            content = content[:8000] + "..."
                        
                        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
                        prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{content}\n\nìš”ì•½:"
                        response = llm.invoke([HumanMessage(content=prompt)])
                        response_content = response.content
                    else:
                        response_content = "ìš”ì•½í•  íŒŒì¼ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
                except Exception as e:
                    response_content = f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    
            elif 'ì •ë³´' in user_lower:
                # íŒŒì¼ ì •ë³´
                response_content = get_document_info_tool_direct()
                
            else:
                # íŒŒì¼ ê²€ìƒ‰
                try:
                    results = safe_search_documents(user_message, 3)
                    if results:
                        formatted_results = []
                        for i, result in enumerate(results, 1):
                            formatted_results.append(
                                f"[ê²€ìƒ‰ê²°ê³¼ {i}] (ìœ ì‚¬ë„: {result['score']:.3f})\n"
                                f"{result['content'][:400]}{'...' if len(result['content']) > 400 else ''}\n"
                            )
                        response_content = "\n".join(formatted_results)
                    else:
                        response_content = f"'{user_message}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                except Exception as e:
                    response_content = f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        
        # ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸
        elif any(keyword in user_lower for keyword in web_keywords):
            try:
                from langchain_community.tools import DuckDuckGoSearchRun
                search_tool = DuckDuckGoSearchRun()
                results = search_tool.run(user_message)
                response_content = f"ğŸŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼:\n\n{results}"
            except ImportError:
                response_content = f"""ğŸ” "{user_message}" ê²€ìƒ‰ ë§í¬:
â€¢ Google: https://www.google.com/search?q={user_message.replace(' ', '+')}
â€¢ ë„¤ì´ë²„: https://search.naver.com/search.naver?query={user_message.replace(' ', '+')}

ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰: pip install duckduckgo-search"""
            except Exception as e:
                response_content = f"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        
        # ì¼ë°˜ ì§ˆë¬¸
        else:
            try:
                llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
                response = llm.invoke([HumanMessage(content=user_message)])
                response_content = response.content
            except Exception as e:
                response_content = f"ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        
        # AI ì‘ë‹µ ìƒì„±
        ai_response = AIMessage(content=response_content)
        return {"messages": messages + [ai_response]}
        
    except Exception as e:
        error_response = AIMessage(content=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return {"messages": messages + [error_response]}

# ê·¸ë˜í”„ ë¹Œë” ìƒì„± (tool calling ì œê±°)
graph_builder = StateGraph(AgentState)
graph_builder.add_node('agent', agent)

graph_builder.add_edge(START, 'agent')
graph_builder.add_edge('agent', END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
graph = graph_builder.compile()

# ============== ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜ ==============

def process_user_input():
    """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜ - ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€"""
    # ì²˜ë¦¬ ì¤‘ì´ë©´ ë¬´ì‹œ
    if st.session_state.processing:
        return
    
    user_input = st.session_state.current_input.strip()
    if not user_input:
        return
    
    # ì²˜ë¦¬ ìƒíƒœ ì„¤ì •
    st.session_state.processing = True
    
    try:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append(("user", user_input))
        
        # AI ì‘ë‹µ ìƒì„±
        if st.session_state.agent_graph is None:
            st.session_state.agent_graph = graph
        
        # ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘ (ì´ì „ ë©”ì‹œì§€ ì²´ì¸ ë¬¸ì œ ë°©ì§€)
        initial_state = {"messages": [HumanMessage(content=user_input)]}
        result = st.session_state.agent_graph.invoke(initial_state)
        
        # ì‘ë‹µ ì¶”ì¶œ (ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ì°¾ê¸°)
        ai_response = None
        if result and "messages" in result:
            # ì—­ìˆœìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ ì²« ë²ˆì§¸ AI ë©”ì‹œì§€ ì°¾ê¸°
            for msg in reversed(result["messages"]):
                if isinstance(msg, AIMessage):
                    ai_response = msg.content
                    break
        
        if ai_response:
            response = ai_response
        else:
            response = "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        st.session_state.chat_history.append(("assistant", response))
        
    except Exception as e:
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        st.session_state.chat_history.append(("assistant", error_msg))
    
    finally:
        # ì…ë ¥ì°½ ì´ˆê¸°í™” ë° ì²˜ë¦¬ ìƒíƒœ í•´ì œ
        st.session_state.current_input = ""
        st.session_state.processing = False

# ============== ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ==============

def handle_quick_summary():
    """íŒŒì¼ ìš”ì•½ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬"""
    if st.session_state.processing:
        return
    
    st.session_state.processing = True
    try:
        response = summarize_content_tool_direct()
        st.session_state.chat_history.append(("user", "ì´ íŒŒì¼ì„ ìš”ì•½í•´ì¤˜"))
        st.session_state.chat_history.append(("assistant", response))
    except Exception as e:
        st.error(f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        st.session_state.processing = False

def handle_quick_info():
    """íŒŒì¼ ì •ë³´ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬"""
    if st.session_state.processing:
        return
    
    st.session_state.processing = True
    try:
        response = get_document_info_tool_direct()
        st.session_state.chat_history.append(("user", "íŒŒì¼ ì •ë³´ë¥¼ ì•Œë ¤ì¤˜"))
        st.session_state.chat_history.append(("assistant", response))
    except Exception as e:
        st.error(f"ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        st.session_state.processing = False

def handle_quick_search():
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬"""
    if st.session_state.processing:
        return
    
    st.session_state.processing = True
    try:
        response = search_uploaded_documents_direct("ì¤‘ìš”í•œ í‚¤ì›Œë“œ")
        st.session_state.chat_history.append(("user", "íŒŒì¼ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ì¤˜"))
        st.session_state.chat_history.append(("assistant", response))
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        st.session_state.processing = False

def handle_quick_file_search():
    """íŒŒì¼ ë‚´ ê²€ìƒ‰ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬"""
    if st.session_state.processing:
        return
    
    st.session_state.processing = True
    try:
        response = "ì–´ë–¤ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
        st.session_state.chat_history.append(("user", "íŒŒì¼ì—ì„œ íŠ¹ì • ë‚´ìš©ì„ ê²€ìƒ‰í•˜ê³  ì‹¶ì–´"))
        st.session_state.chat_history.append(("assistant", response))
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        st.session_state.processing = False

def handle_quick_python():
    """íŒŒì´ì¬ ì§ˆë¬¸ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬"""
    if st.session_state.processing:
        return
    
    st.session_state.processing = True
    try:
        response = general_chat_tool_direct("íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€?")
        st.session_state.chat_history.append(("user", "íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€?"))
        st.session_state.chat_history.append(("assistant", response))
    except Exception as e:
        st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        st.session_state.processing = False

def handle_quick_web_search():
    """ì›¹ ê²€ìƒ‰ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬"""
    if st.session_state.processing:
        return
    
    st.session_state.processing = True
    try:
        response = web_search_tool_direct("ìµœì‹  AI ë‰´ìŠ¤")
        st.session_state.chat_history.append(("user", "ìµœì‹  AI ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜"))
        st.session_state.chat_history.append(("assistant", response))
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        st.session_state.processing = False

def handle_quick_ai_question():
    """AI ì§ˆë¬¸ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬"""
    if st.session_state.processing:
        return
    
    st.session_state.processing = True
    try:
        response = general_chat_tool_direct("ChatGPTì™€ Claudeì˜ ì°¨ì´ì ì€?")
        st.session_state.chat_history.append(("user", "ChatGPTì™€ Claudeì˜ ì°¨ì´ì ì€?"))
        st.session_state.chat_history.append(("assistant", response))
    except Exception as e:
        st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        st.session_state.processing = False

def handle_quick_coding():
    """ì½”ë”© ì§ˆë¬¸ ë¹ ë¥¸ ë²„íŠ¼ ì²˜ë¦¬"""
    if st.session_state.processing:
        return
    
    st.session_state.processing = True
    try:
        response = general_chat_tool_direct("íŒŒì´ì¬ í´ë˜ìŠ¤ì™€ ê°ì²´ì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì¤˜")
        st.session_state.chat_history.append(("user", "íŒŒì´ì¬ í´ë˜ìŠ¤ì™€ ê°ì²´ì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì¤˜"))
        st.session_state.chat_history.append(("assistant", response))
    except Exception as e:
        st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        st.session_state.processing = False

# ============== Streamlit UI ==============

def main():
    st.title("ğŸ¤– íŒŒì¼ ë¶„ì„ AI ì–´ì‹œìŠ¤í„´íŠ¸")
    st.markdown("---")
    
    # API í‚¤ ì²´í¬
    if not os.getenv('OPENAI_API_KEY'):
        st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['pdf', 'txt', 'md', 'py', 'js', 'html', 'css', 'json', 'xml', 'csv'],
            help="PDF, í…ìŠ¤íŠ¸ íŒŒì¼, ì½”ë“œ íŒŒì¼ ë“±ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        if uploaded_file is not None:
            st.info(f"ğŸ“ ì„ íƒëœ íŒŒì¼: {uploaded_file.name}")
            st.info(f"ğŸ“ íŒŒì¼ í¬ê¸°: {uploaded_file.size:,} bytes")
            
            if st.button("ğŸ“Š íŒŒì¼ ë¶„ì„ ì‹œì‘", type="primary"):
                with st.spinner("íŒŒì¼ì„ ë¶„ì„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        full_text = extract_text_from_file(uploaded_file)
                        
                        if full_text:
                            # ì²­í‚¹
                            st.session_state.chunks = chunk_text(full_text)
                            st.info(f"âœ… ì²­í‚¹ ì™„ë£Œ! ì´ {len(st.session_state.chunks)}ê°œ ì²­í¬ ìƒì„±")
                            
                            # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
                            index, embedding_model, metadatas = create_vectorstore(st.session_state.chunks)
                            
                            if index is not None:
                                st.session_state.index = index
                                st.session_state.embedding_model = embedding_model
                                st.session_state.metadatas = metadatas
                                st.session_state.file_processed = True
                                st.session_state.uploaded_filename = uploaded_file.name
                                
                                st.success("ğŸ‰ íŒŒì¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                                st.balloons()
                    except Exception as e:
                        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ë¬¸ì„œ ì •ë³´ í‘œì‹œ
        if st.session_state.file_processed:
            st.markdown("---")
            st.header("ğŸ“Š íŒŒì¼ ì •ë³´")
            
            if hasattr(st.session_state, 'uploaded_filename'):
                st.info(f"ğŸ“ íŒŒì¼ëª…: {st.session_state.uploaded_filename}")
            
            if st.session_state.chunks:
                total_chars = sum(len(chunk) for chunk in st.session_state.chunks)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("ì²­í¬ ìˆ˜", len(st.session_state.chunks))
                with col2:
                    st.metric("ì´ ê¸€ì ìˆ˜", f"{total_chars:,}")
            
            # ì´ˆê¸°í™” ë²„íŠ¼
            if st.button("ğŸ”„ ì´ˆê¸°í™”", help="ì—…ë¡œë“œëœ íŒŒì¼ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤"):
                for key in ['chunks', 'index', 'embedding_model', 'metadatas', 'file_processed', 'chat_history', 'uploaded_filename', 'file_metadata', 'pdf_metadata', 'current_input', 'processing']:
                    if key in st.session_state:
                        del st.session_state[key]
                st.rerun()
    
    # ë©”ì¸ ì½˜í…ì¸  - í•­ìƒ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ
    st.header("ğŸ’¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì™€ ëŒ€í™”í•˜ê¸°")
    
    if not st.session_state.file_processed:
        st.info("ğŸ’¡ ì¼ë°˜ ì§ˆë¬¸ë„ ê°€ëŠ¥í•˜ê³ , íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ íŒŒì¼ ë¶„ì„ë„ í•  ìˆ˜ ìˆì–´ìš”!")
        
        # ì‚¬ìš©ë²• ì•ˆë‚´
        with st.expander("ğŸ“– ì‚¬ìš©ë²• ì•ˆë‚´", expanded=False):
            st.markdown("""
            ### ğŸš€ ë‘ ê°€ì§€ ì‚¬ìš© ë°©ë²•
            
            #### 1ï¸âƒ£ ì¼ë°˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ì‚¬ìš©
            - ë°”ë¡œ ì•„ë˜ì—ì„œ ì§ˆë¬¸í•˜ì„¸ìš”!
            - ì›¹ ê²€ìƒ‰, ì¼ë°˜ ì§€ì‹ ì§ˆë¬¸ ë“± ëª¨ë“  ì§ˆë¬¸ ê°€ëŠ¥
            
            #### 2ï¸âƒ£ íŒŒì¼ ë¶„ì„ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
            1. **íŒŒì¼ ì—…ë¡œë“œ**: ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
               - ğŸ“„ **PDF**: ë¬¸ì„œ, ë…¼ë¬¸, ë³´ê³ ì„œ ë“±
               - ğŸ“ **í…ìŠ¤íŠ¸**: .txt, .md íŒŒì¼
               - ğŸ’» **ì½”ë“œ**: .py, .js, .html, .css, .json ë“±
               - ğŸ“Š **ë°ì´í„°**: .csv, .xml ë“±
            2. **ë¶„ì„ ì‹œì‘**: "íŒŒì¼ ë¶„ì„ ì‹œì‘" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
            3. **íŒŒì¼ ì§ˆë¬¸**: ì—…ë¡œë“œí•œ íŒŒì¼ì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
            
            ### ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸
            **ì¼ë°˜ ì§ˆë¬¸:**
            - "íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€?"
            - "ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì–´ë•Œ?"
            - "ìµœì‹  AI ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜"
            
            **íŒŒì¼ ì§ˆë¬¸ (ì—…ë¡œë“œ í›„):**
            - "ì´ íŒŒì¼ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜"
            - "ì½”ë“œì—ì„œ í•¨ìˆ˜ë“¤ì„ ì„¤ëª…í•´ì¤˜"
            - "íŒŒì¼ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ì¤˜"
            - "ì´ ë°ì´í„°ì˜ íŒ¨í„´ì„ ë¶„ì„í•´ì¤˜"
            """)
    
    # ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì´ˆê¸°í™” (ëª¨ë“  tool í•¨ìˆ˜ê°€ ì •ì˜ëœ í›„ì— ì‹¤í–‰)
    try:
        if st.session_state.agent_graph is None:
            st.session_state.agent_graph = graph
    except Exception as e:
        st.error(f"AI ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
        st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.")
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    chat_container = st.container()
    
    with chat_container:
        for i, (role, message) in enumerate(st.session_state.chat_history):
            if role == "user":
                with st.chat_message("user"):
                    st.write(message)
            else:
                with st.chat_message("assistant"):
                    st.write(message)
    
    # ì‚¬ìš©ì ì…ë ¥ (í•­ìƒ ë§¨ ì•„ë˜ì— ê³ ì •)
    st.markdown("---")
    st.subheader("âœï¸ ì§ˆë¬¸í•˜ê¸°")
    
    # í…ìŠ¤íŠ¸ ì…ë ¥ê³¼ ë²„íŠ¼ì„ ê°™ì€ í–‰ì— ë°°ì¹˜
    col1, col2 = st.columns([4, 1])
    
    with col1:
        # on_change ì½œë°±ì„ ì‚¬ìš©í•˜ì—¬ ì—”í„°í‚¤ ì²˜ë¦¬
        user_input = st.text_input(
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            value=st.session_state.current_input,
            placeholder="ì˜ˆ: 'íŒŒì´ì¬ì´ë€?' ë˜ëŠ” 'íŒŒì¼ì„ ìš”ì•½í•´ì¤˜' (Enter ë˜ëŠ” ì „ì†¡ ë²„íŠ¼)",
            key="text_input",
            on_change=process_user_input
        )
        # ì…ë ¥ê°’ì„ ì„¸ì…˜ ìƒíƒœì— ë™ê¸°í™”
        st.session_state.current_input = user_input
    
    with col2:
        # ì „ì†¡ ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬
        if st.button("ì „ì†¡", type="primary", use_container_width=True):
            process_user_input()
            st.rerun()
    
    # ë¹ ë¥¸ ì§ˆë¬¸ ë²„íŠ¼ë“¤
    st.markdown("---")
    
    if st.session_state.file_processed:
        st.subheader("ğŸ¯ íŒŒì¼ ê´€ë ¨ ë¹ ë¥¸ ì§ˆë¬¸")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("ğŸ“ íŒŒì¼ ìš”ì•½", on_click=handle_quick_summary):
                st.rerun()
        
        with col2:
            if st.button("ğŸ“Š íŒŒì¼ ì •ë³´", on_click=handle_quick_info):
                st.rerun()
        
        with col3:
            if st.button("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰", on_click=handle_quick_search):
                st.rerun()
        
        with col4:
            if st.button("ğŸ“„ íŒŒì¼ ë‚´ ê²€ìƒ‰", on_click=handle_quick_file_search):
                st.rerun()
    
    else:
        st.subheader("ğŸ¯ ì¼ë°˜ ì§ˆë¬¸ ì˜ˆì‹œ")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("ğŸ íŒŒì´ì¬ ì§ˆë¬¸", on_click=handle_quick_python):
                st.rerun()
        
        with col2:
            if st.button("ğŸŒ ì›¹ ê²€ìƒ‰", on_click=handle_quick_web_search):
                st.rerun()
        
        with col3:
            if st.button("ğŸ¤– AI ì§ˆë¬¸", on_click=handle_quick_ai_question):
                st.rerun()
        
        with col4:
            if st.button("ğŸ’» ì½”ë”© ì§ˆë¬¸", on_click=handle_quick_coding):
                st.rerun()

if __name__ == "__main__":
    main()
    
    
